{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "MyUnet.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "GKFzmhQ-4X08",
        "colab_type": "code",
        "outputId": "191edb76-6006-4b4b-f804-ba7ff7d2f745",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "source": [
        "### FIRST THING FIRST COMES AUTHENTICATION\n",
        "# Install the PyDrive wrapper & import libraries.\n",
        "# This only needs to be done once in a notebook.\n",
        "!pip install -U -q PyDrive\n",
        "from pydrive.auth import GoogleAuth\n",
        "from pydrive.drive import GoogleDrive\n",
        "from google.colab import auth\n",
        "from oauth2client.client import GoogleCredentials\n",
        "\n",
        "# Authenticate and create the PyDrive client.\n",
        "# This only needs to be done once in a notebook.\n",
        "auth.authenticate_user()\n",
        "gauth = GoogleAuth()\n",
        "gauth.credentials = GoogleCredentials.get_application_default()\n",
        "drive = GoogleDrive(gauth)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[?25l\r\u001b[K     |▎                               | 10kB 18.9MB/s eta 0:00:01\r\u001b[K     |▋                               | 20kB 4.3MB/s eta 0:00:01\r\u001b[K     |█                               | 30kB 6.2MB/s eta 0:00:01\r\u001b[K     |█▎                              | 40kB 4.0MB/s eta 0:00:01\r\u001b[K     |█▋                              | 51kB 4.9MB/s eta 0:00:01\r\u001b[K     |██                              | 61kB 5.7MB/s eta 0:00:01\r\u001b[K     |██▎                             | 71kB 6.5MB/s eta 0:00:01\r\u001b[K     |██▋                             | 81kB 7.3MB/s eta 0:00:01\r\u001b[K     |███                             | 92kB 5.9MB/s eta 0:00:01\r\u001b[K     |███▎                            | 102kB 6.4MB/s eta 0:00:01\r\u001b[K     |███▋                            | 112kB 6.4MB/s eta 0:00:01\r\u001b[K     |████                            | 122kB 6.4MB/s eta 0:00:01\r\u001b[K     |████▎                           | 133kB 6.4MB/s eta 0:00:01\r\u001b[K     |████▋                           | 143kB 6.4MB/s eta 0:00:01\r\u001b[K     |█████                           | 153kB 6.4MB/s eta 0:00:01\r\u001b[K     |█████▎                          | 163kB 6.4MB/s eta 0:00:01\r\u001b[K     |█████▋                          | 174kB 6.4MB/s eta 0:00:01\r\u001b[K     |██████                          | 184kB 6.4MB/s eta 0:00:01\r\u001b[K     |██████▎                         | 194kB 6.4MB/s eta 0:00:01\r\u001b[K     |██████▋                         | 204kB 6.4MB/s eta 0:00:01\r\u001b[K     |███████                         | 215kB 6.4MB/s eta 0:00:01\r\u001b[K     |███████▎                        | 225kB 6.4MB/s eta 0:00:01\r\u001b[K     |███████▋                        | 235kB 6.4MB/s eta 0:00:01\r\u001b[K     |████████                        | 245kB 6.4MB/s eta 0:00:01\r\u001b[K     |████████▎                       | 256kB 6.4MB/s eta 0:00:01\r\u001b[K     |████████▋                       | 266kB 6.4MB/s eta 0:00:01\r\u001b[K     |█████████                       | 276kB 6.4MB/s eta 0:00:01\r\u001b[K     |█████████▎                      | 286kB 6.4MB/s eta 0:00:01\r\u001b[K     |█████████▋                      | 296kB 6.4MB/s eta 0:00:01\r\u001b[K     |██████████                      | 307kB 6.4MB/s eta 0:00:01\r\u001b[K     |██████████▎                     | 317kB 6.4MB/s eta 0:00:01\r\u001b[K     |██████████▋                     | 327kB 6.4MB/s eta 0:00:01\r\u001b[K     |███████████                     | 337kB 6.4MB/s eta 0:00:01\r\u001b[K     |███████████▎                    | 348kB 6.4MB/s eta 0:00:01\r\u001b[K     |███████████▋                    | 358kB 6.4MB/s eta 0:00:01\r\u001b[K     |████████████                    | 368kB 6.4MB/s eta 0:00:01\r\u001b[K     |████████████▎                   | 378kB 6.4MB/s eta 0:00:01\r\u001b[K     |████████████▋                   | 389kB 6.4MB/s eta 0:00:01\r\u001b[K     |█████████████                   | 399kB 6.4MB/s eta 0:00:01\r\u001b[K     |█████████████▎                  | 409kB 6.4MB/s eta 0:00:01\r\u001b[K     |█████████████▋                  | 419kB 6.4MB/s eta 0:00:01\r\u001b[K     |██████████████                  | 430kB 6.4MB/s eta 0:00:01\r\u001b[K     |██████████████▎                 | 440kB 6.4MB/s eta 0:00:01\r\u001b[K     |██████████████▋                 | 450kB 6.4MB/s eta 0:00:01\r\u001b[K     |███████████████                 | 460kB 6.4MB/s eta 0:00:01\r\u001b[K     |███████████████▎                | 471kB 6.4MB/s eta 0:00:01\r\u001b[K     |███████████████▋                | 481kB 6.4MB/s eta 0:00:01\r\u001b[K     |████████████████                | 491kB 6.4MB/s eta 0:00:01\r\u001b[K     |████████████████▎               | 501kB 6.4MB/s eta 0:00:01\r\u001b[K     |████████████████▋               | 512kB 6.4MB/s eta 0:00:01\r\u001b[K     |█████████████████               | 522kB 6.4MB/s eta 0:00:01\r\u001b[K     |█████████████████▎              | 532kB 6.4MB/s eta 0:00:01\r\u001b[K     |█████████████████▋              | 542kB 6.4MB/s eta 0:00:01\r\u001b[K     |██████████████████              | 552kB 6.4MB/s eta 0:00:01\r\u001b[K     |██████████████████▎             | 563kB 6.4MB/s eta 0:00:01\r\u001b[K     |██████████████████▋             | 573kB 6.4MB/s eta 0:00:01\r\u001b[K     |███████████████████             | 583kB 6.4MB/s eta 0:00:01\r\u001b[K     |███████████████████▎            | 593kB 6.4MB/s eta 0:00:01\r\u001b[K     |███████████████████▋            | 604kB 6.4MB/s eta 0:00:01\r\u001b[K     |████████████████████            | 614kB 6.4MB/s eta 0:00:01\r\u001b[K     |████████████████████▎           | 624kB 6.4MB/s eta 0:00:01\r\u001b[K     |████████████████████▋           | 634kB 6.4MB/s eta 0:00:01\r\u001b[K     |█████████████████████           | 645kB 6.4MB/s eta 0:00:01\r\u001b[K     |█████████████████████▎          | 655kB 6.4MB/s eta 0:00:01\r\u001b[K     |█████████████████████▋          | 665kB 6.4MB/s eta 0:00:01\r\u001b[K     |██████████████████████          | 675kB 6.4MB/s eta 0:00:01\r\u001b[K     |██████████████████████▎         | 686kB 6.4MB/s eta 0:00:01\r\u001b[K     |██████████████████████▋         | 696kB 6.4MB/s eta 0:00:01\r\u001b[K     |███████████████████████         | 706kB 6.4MB/s eta 0:00:01\r\u001b[K     |███████████████████████▎        | 716kB 6.4MB/s eta 0:00:01\r\u001b[K     |███████████████████████▋        | 727kB 6.4MB/s eta 0:00:01\r\u001b[K     |████████████████████████        | 737kB 6.4MB/s eta 0:00:01\r\u001b[K     |████████████████████████▎       | 747kB 6.4MB/s eta 0:00:01\r\u001b[K     |████████████████████████▋       | 757kB 6.4MB/s eta 0:00:01\r\u001b[K     |████████████████████████▉       | 768kB 6.4MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▏      | 778kB 6.4MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▌      | 788kB 6.4MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▉      | 798kB 6.4MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▏     | 808kB 6.4MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▌     | 819kB 6.4MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▉     | 829kB 6.4MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▏    | 839kB 6.4MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▌    | 849kB 6.4MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▉    | 860kB 6.4MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▏   | 870kB 6.4MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▌   | 880kB 6.4MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▉   | 890kB 6.4MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▏  | 901kB 6.4MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▌  | 911kB 6.4MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▉  | 921kB 6.4MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▏ | 931kB 6.4MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▌ | 942kB 6.4MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▉ | 952kB 6.4MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▏| 962kB 6.4MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▌| 972kB 6.4MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▉| 983kB 6.4MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 993kB 6.4MB/s \n",
            "\u001b[?25h  Building wheel for PyDrive (setup.py) ... \u001b[?25l\u001b[?25hdone\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1Bp9pBnJ7JHX",
        "colab_type": "code",
        "outputId": "1410e439-4f74-48cf-9443-1e076be75580",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        }
      },
      "source": [
        "fileTraining = drive.CreateFile({'id': '1jqjHB2QYwh7eTEqWEB5QFCcbNNkhOPXA'}) \n",
        "fileTraining.GetContentFile(fileTraining['title'])  # Save Drive file as a local file\n",
        "print('Uploaded {}, id {}'.format(fileTraining['title'], fileTraining['id']))\n",
        "\n",
        "\n",
        "fileGroundTruth = drive.CreateFile({'id': '18yJQH7ksJy4QMZ9UCMCQrApuKq93C7jw'}) \n",
        "fileGroundTruth.GetContentFile(fileGroundTruth['title'])  # Save Drive file as a local file\n",
        "print('Uploaded {}, id {}'.format(fileGroundTruth['title'], fileGroundTruth['id']))\n",
        "\n",
        "\n",
        "\n",
        "# file train\n",
        "# https://drive.google.com/open?id=1jqjHB2QYwh7eTEqWEB5QFCcbNNkhOPXA\n",
        "# file groundtruth\n",
        "# https://drive.google.com/open?id=18yJQH7ksJy4QMZ9UCMCQrApuKq93C7jw\n",
        "\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Uploaded training_data.zip, id 1jqjHB2QYwh7eTEqWEB5QFCcbNNkhOPXA\n",
            "Uploaded ground_truth_data.zip, id 18yJQH7ksJy4QMZ9UCMCQrApuKq93C7jw\n",
            "Uploaded myunet_saved.hdf5, id 1y1CRLYcb2zqqdmF3XSr3kQ9k3HurrkdQ\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZbmUlebU8r3S",
        "colab_type": "code",
        "outputId": "e5994b6f-39fd-4797-ef9c-4b4af9705a48",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 425
        }
      },
      "source": [
        "!unzip ground_truth_data\n",
        "!unzip training_data"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Archive:  ground_truth_data.zip\n",
            "  inflating: training_sa_crop_pat5-label.nii  \n",
            "  inflating: training_sa_crop_pat6-label.nii  \n",
            "  inflating: training_sa_crop_pat7-label.nii  \n",
            "  inflating: training_sa_crop_pat8-label.nii  \n",
            "  inflating: training_sa_crop_pat9-label.nii  \n",
            "  inflating: training_sa_crop_pat0-label.nii  \n",
            "  inflating: training_sa_crop_pat1-label.nii  \n",
            "  inflating: training_sa_crop_pat2-label.nii  \n",
            "  inflating: training_sa_crop_pat3-label.nii  \n",
            "  inflating: training_sa_crop_pat4-label.nii  \n",
            "Archive:  training_data.zip\n",
            "  inflating: training_sa_crop_pat6.nii  \n",
            "  inflating: training_sa_crop_pat7.nii  \n",
            "  inflating: training_sa_crop_pat8.nii  \n",
            "  inflating: training_sa_crop_pat9.nii  \n",
            "  inflating: training_sa_crop_pat0.nii  \n",
            "  inflating: training_sa_crop_pat1.nii  \n",
            "  inflating: training_sa_crop_pat2.nii  \n",
            "  inflating: training_sa_crop_pat3.nii  \n",
            "  inflating: training_sa_crop_pat4.nii  \n",
            "  inflating: training_sa_crop_pat5.nii  \n",
            "unzip:  cannot find or open pesi_fcn_unet, pesi_fcn_unet.zip or pesi_fcn_unet.ZIP.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "luec_5jkyjvm",
        "colab_type": "code",
        "outputId": "38b9ae07-5d7a-4dd7-9782-792443ea08dd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "import os\n",
        "from google.colab import drive\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.pyplot as plt_prediction\n",
        "import matplotlib.pyplot as plt_maschera\n",
        "from google.colab.patches import cv2_imshow\n",
        "from keras import backend as K\n",
        "from keras import layers\n",
        "from keras.layers import Activation\n",
        "from keras.layers import Input, Conv2D, ZeroPadding2D, MaxPooling2D, UpSampling2D, concatenate\n",
        "from keras.layers.normalization import BatchNormalization\n",
        "from keras.models import Model\n",
        "from keras.optimizers import Adam\n",
        "from PIL import Image\n",
        "from keras.preprocessing.image import load_img\n",
        "import numpy as np\n",
        "import nibabel as nib\n",
        "from google.colab import files\n",
        "from PIL import Image\n",
        "import PIL.ImageOps  \n",
        "from scipy.ndimage import zoom\n",
        "from keras import losses"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R8KumY6AQj54",
        "colab_type": "code",
        "outputId": "34217f70-8d4b-4b8d-afb7-1607ecf5ed8e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "img_rows = 128\n",
        "img_cols = 160\n",
        "\n",
        "array_training = np.zeros((207,128,160))\n",
        "array_gt = np.zeros((207,128,160))\n",
        "\n",
        "for x in range (10):\n",
        "  img_training = nib.load('../content/training_sa_crop_pat%d.nii' % (x))\n",
        "  img_gt = nib.load('../content/training_sa_crop_pat%d-label.nii' % (x))\n",
        "  array_img_training = np.array(img_training.dataobj)\n",
        "  array_img_gt = np.array(img_gt.dataobj)\n",
        "  array_img_training=np.swapaxes(array_img_training,0,1)\n",
        "  array_img_gt=np.swapaxes(array_img_gt,0,1)\n",
        "  print(\"shape img training %d: \" % (x))\n",
        "  print(array_img_training.shape)\n",
        "  print(\"shape img gt %d: \" % (x))\n",
        "  print(array_img_gt.shape)\n",
        "  \n",
        "  array_img_training = zoom(array_img_training, (1, 128/array_img_training.shape[1], 160/array_img_training.shape[2]))\n",
        "  array_img_gt = zoom(array_img_gt, (1, 128/array_img_gt.shape[1], 160/array_img_gt.shape[2]))\n",
        "  print(\"NUOVO shape img training %d: \" % (x))\n",
        "  print(array_img_training.shape)\n",
        "  print(\"NUOVO shape img gt %d: \" % (x))\n",
        "  print(array_img_gt.shape)\n",
        "  if (x == 0):\n",
        "    array_training = array_img_training\n",
        "    array_gt = array_img_gt\n",
        "  else :\n",
        "    array_training = np.concatenate((array_training, array_img_training), axis = 0)\n",
        "    array_gt = np.concatenate((array_gt, array_img_gt), axis = 0)\n",
        "    \n",
        "print(\"--> shape array training finale concatenato: \")\n",
        "print(array_training.shape)\n",
        "print(\"--> shape array gt finale concatenato: \")\n",
        "print(array_gt.shape)\n",
        "  \n",
        "array_training = array_training.reshape((array_training.shape[0], array_training.shape[1], array_training.shape[2],1))\n",
        "\n",
        "#preprocessing delle immagini\n",
        "array_training = array_training.astype('float32')\n",
        "mean = np.mean(array_training)\n",
        "std = np.std(array_training)\n",
        "\n",
        "array_training -= mean\n",
        "array_training /= std\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "shape img training 0: \n",
            "(207, 127, 151)\n",
            "shape img gt 0: \n",
            "(207, 127, 151)\n",
            "NUOVO shape img training 0: \n",
            "(207, 128, 160)\n",
            "NUOVO shape img gt 0: \n",
            "(207, 128, 160)\n",
            "shape img training 1: \n",
            "(220, 127, 160)\n",
            "shape img gt 1: \n",
            "(220, 127, 160)\n",
            "NUOVO shape img training 1: \n",
            "(220, 128, 160)\n",
            "NUOVO shape img gt 1: \n",
            "(220, 128, 160)\n",
            "shape img training 2: \n",
            "(231, 118, 190)\n",
            "shape img gt 2: \n",
            "(231, 118, 190)\n",
            "NUOVO shape img training 2: \n",
            "(231, 128, 160)\n",
            "NUOVO shape img gt 2: \n",
            "(231, 128, 160)\n",
            "shape img training 3: \n",
            "(175, 150, 148)\n",
            "shape img gt 3: \n",
            "(175, 150, 148)\n",
            "NUOVO shape img training 3: \n",
            "(175, 128, 160)\n",
            "NUOVO shape img gt 3: \n",
            "(175, 128, 160)\n",
            "shape img training 4: \n",
            "(105, 95, 130)\n",
            "shape img gt 4: \n",
            "(105, 95, 130)\n",
            "NUOVO shape img training 4: \n",
            "(105, 128, 160)\n",
            "NUOVO shape img gt 4: \n",
            "(105, 128, 160)\n",
            "shape img training 5: \n",
            "(120, 97, 164)\n",
            "shape img gt 5: \n",
            "(120, 97, 164)\n",
            "NUOVO shape img training 5: \n",
            "(120, 128, 160)\n",
            "NUOVO shape img gt 5: \n",
            "(120, 128, 160)\n",
            "shape img training 6: \n",
            "(230, 150, 170)\n",
            "shape img gt 6: \n",
            "(230, 150, 170)\n",
            "NUOVO shape img training 6: \n",
            "(230, 128, 160)\n",
            "NUOVO shape img gt 6: \n",
            "(230, 128, 160)\n",
            "shape img training 7: \n",
            "(250, 165, 200)\n",
            "shape img gt 7: \n",
            "(250, 165, 200)\n",
            "NUOVO shape img training 7: \n",
            "(250, 128, 160)\n",
            "NUOVO shape img gt 7: \n",
            "(250, 128, 160)\n",
            "shape img training 8: \n",
            "(190, 140, 150)\n",
            "shape img gt 8: \n",
            "(190, 140, 150)\n",
            "NUOVO shape img training 8: \n",
            "(190, 128, 160)\n",
            "NUOVO shape img gt 8: \n",
            "(190, 128, 160)\n",
            "shape img training 9: \n",
            "(200, 170, 165)\n",
            "shape img gt 9: \n",
            "(200, 170, 165)\n",
            "NUOVO shape img training 9: \n",
            "(200, 128, 160)\n",
            "NUOVO shape img gt 9: \n",
            "(200, 128, 160)\n",
            "--> shape array training finale concatenato: \n",
            "(1928, 128, 160)\n",
            "--> shape array gt finale concatenato: \n",
            "(1928, 128, 160)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gLGYV9_uz2BR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def dice_coef(y_true, y_pred, smooth=0.0):\n",
        "    \"\"\"Average dice coefficient per batch.\"\"\"\n",
        "    axes = (1, 2, 3)\n",
        "    intersection = K.sum(y_true * y_pred, axis=axes)\n",
        "    summation = K.sum(y_true, axis=axes) + K.sum(y_pred, axis=axes)\n",
        "    \n",
        "    return K.mean((2.0 * intersection + smooth) / (summation + smooth), axis=0)\n",
        "  \n",
        "\n",
        "     \n",
        "def dice_coef_loss(y_true, y_pred):\n",
        "    return -dice_coef(y_true, y_pred)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g_KZFdv3ZjSS",
        "colab_type": "text"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b-wgKrybz1-9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def up_conv_block(input_tensor, kernel_size, filters, stage, block, strides=(1, 1)):\n",
        "    filters1, filters2, filters3 = filters\n",
        "    if K.image_data_format() == 'channels_last':\n",
        "        bn_axis = 3\n",
        "    else:\n",
        "        bn_axis = 1\n",
        "    up_conv_name_base = 'up' + str(stage) + block + '_branch'\n",
        "    conv_name_base = 'res' + str(stage) + block + '_branch'\n",
        "    bn_name_base = 'bn' + str(stage) + block + '_branch'\n",
        "\n",
        "    x = UpSampling2D(size=(2, 2), name=up_conv_name_base + '2a')(input_tensor)\n",
        "\n",
        "    x = Conv2D(filters1, (1, 1), strides=strides, name=conv_name_base + '2a')(x)\n",
        "\n",
        "    x = BatchNormalization(axis=bn_axis, name=bn_name_base + '2a')(x)\n",
        "    x = Activation('relu')(x)\n",
        "\n",
        "    x = Conv2D(filters2, kernel_size, padding='same', name=conv_name_base + '2b')(x)\n",
        "    x = BatchNormalization(axis=bn_axis, name=bn_name_base + '2b')(x)\n",
        "    x = Activation('relu')(x)\n",
        "\n",
        "    x = Conv2D(filters3, (1, 1), name=conv_name_base + '2c')(x)\n",
        "    x = BatchNormalization(axis=bn_axis, name=bn_name_base + '2c')(x)\n",
        "\n",
        "    shortcut = UpSampling2D(size=(2, 2), name=up_conv_name_base + '1')(input_tensor)\n",
        "    shortcut = Conv2D(filters3, (1, 1), strides=strides, name=conv_name_base + '1')(shortcut)\n",
        "    shortcut = BatchNormalization(axis=bn_axis, name=bn_name_base + '1')(shortcut)\n",
        "\n",
        "    x = layers.add([x, shortcut])\n",
        "    x = Activation('relu')(x)\n",
        "    return x\n",
        "  \n",
        "def identity_block(input_tensor, kernel_size, filters, stage, block):\n",
        "    filters1, filters2, filters3 = filters\n",
        "    if K.image_data_format() == 'channels_last':\n",
        "        bn_axis = 3\n",
        "    else:\n",
        "        bn_axis = 1\n",
        "    conv_name_base = 'res' + str(stage) + block + '_branch'\n",
        "    bn_name_base = 'bn' + str(stage) + block + '_branch'\n",
        "\n",
        "    x = Conv2D(filters1, (1, 1), name=conv_name_base + '2a')(input_tensor)\n",
        "    x = BatchNormalization(axis=bn_axis, name=bn_name_base + '2a')(x)\n",
        "    x = Activation('relu')(x)\n",
        "\n",
        "    x = Conv2D(filters2, kernel_size, padding='same', name=conv_name_base + '2b')(x)\n",
        "    x = BatchNormalization(axis=bn_axis, name=bn_name_base + '2b')(x)\n",
        "    x = Activation('relu')(x)\n",
        "\n",
        "    x = Conv2D(filters3, (1, 1), name=conv_name_base + '2c')(x)\n",
        "    x = BatchNormalization(axis=bn_axis, name=bn_name_base + '2c')(x)\n",
        "\n",
        "    x = layers.add([x, input_tensor])\n",
        "    x = Activation('relu')(x)\n",
        "    return x\n",
        "\n",
        "\n",
        "def conv_block(input_tensor, kernel_size, filters, stage, block, strides=(2, 2)):\n",
        "    filters1, filters2, filters3 = filters\n",
        "    if K.image_data_format() == 'channels_last':\n",
        "        bn_axis = 3\n",
        "    else:\n",
        "        bn_axis = 1\n",
        "    conv_name_base = 'res' + str(stage) + block + '_branch'\n",
        "    bn_name_base = 'bn' + str(stage) + block + '_branch'\n",
        "\n",
        "    x = Conv2D(filters1, (1, 1), strides=strides, name=conv_name_base + '2a')(input_tensor)\n",
        "    x = BatchNormalization(axis=bn_axis, name=bn_name_base + '2a')(x)\n",
        "    x = Activation('relu')(x)\n",
        "\n",
        "    x = Conv2D(filters2, kernel_size, padding='same', name=conv_name_base + '2b')(x)\n",
        "    x = BatchNormalization(axis=bn_axis, name=bn_name_base + '2b')(x)\n",
        "    x = Activation('relu')(x)\n",
        "\n",
        "    x = Conv2D(filters3, (1, 1), name=conv_name_base + '2c')(x)\n",
        "    x = BatchNormalization(axis=bn_axis, name=bn_name_base + '2c')(x)\n",
        "\n",
        "    shortcut = Conv2D(filters3, (1, 1), strides=strides, name=conv_name_base + '1')(input_tensor)\n",
        "    shortcut = BatchNormalization(axis=bn_axis, name=bn_name_base + '1')(shortcut)\n",
        "\n",
        "    x = layers.add([x, shortcut])\n",
        "    x = Activation('relu')(x)\n",
        "    return x\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bpR3Kqwryj7W",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def get_resnet(f=16, bn_axis=3, classes=3):\n",
        "    input = Input((img_rows, img_cols, 1))\n",
        "    x = ZeroPadding2D((4, 4))(input)\n",
        "    \n",
        "    x = Conv2D(f, (7, 7), strides=(2, 2), name='conv1')(x)\n",
        "\n",
        "    x = BatchNormalization(axis=bn_axis, name='bn_conv1')(x)\n",
        "    x = Activation('relu')(x)\n",
        "    x = MaxPooling2D((3, 3), strides=(2, 2))(x)\n",
        "    \n",
        "    x = conv_block(x, 3, [f, f, f * 2], stage=2, block='a', strides=(1, 1))\n",
        "    x = identity_block(x, 3, [f, f, f * 2], stage=2, block='b')\n",
        "    x2 = identity_block(x, 3, [f, f, f * 2], stage=2, block='c')\n",
        "\n",
        "    x = conv_block(x2, 3, [f * 2, f * 2, f * 4], stage=3, block='a')\n",
        "    x = identity_block(x, 3, [f * 2, f * 2, f * 4], stage=3, block='b')\n",
        "    x3 = identity_block(x, 3, [f * 2, f * 2, f * 4], stage=3, block='d')\n",
        "\n",
        "    x = conv_block(x3, 3, [f * 4, f * 4, f * 8], stage=4, block='a')\n",
        "    x = identity_block(x, 3, [f * 4, f * 4, f * 8], stage=4, block='b')\n",
        "    x4 = identity_block(x, 3, [f * 4, f * 4, f * 8], stage=4, block='f')\n",
        "\n",
        "    x = conv_block(x4, 3, [f * 8, f * 8, f * 16], stage=5, block='a')\n",
        "    x = identity_block(x, 3, [f * 8, f * 8, f * 16], stage=5, block='b')\n",
        "    x = identity_block(x, 3, [f * 8, f * 8, f * 16], stage=5, block='c')\n",
        "\n",
        "    x = up_conv_block(x, 3, [f * 16, f * 8, f * 8], stage=6, block='a')\n",
        "    x = identity_block(x, 3, [f * 16, f * 8, f * 8], stage=6, block='b')\n",
        "    x = identity_block(x, 3, [f * 16, f * 8, f * 8], stage=6, block='c')\n",
        "    \n",
        "    x = concatenate([x, x4], axis=bn_axis)\n",
        "\n",
        "    x = up_conv_block(x, 3, [f * 16, f * 4, f * 4], stage=7, block='a')\n",
        "    x = identity_block(x, 3, [f * 16, f * 4, f * 4], stage=7, block='b')\n",
        "\n",
        "    x = identity_block(x, 3, [f * 16, f * 4, f * 4], stage=7, block='f')\n",
        "    x = concatenate([x, x3], axis=bn_axis)\n",
        "\n",
        "    x = up_conv_block(x, 3, [f * 8, f * 2, f * 2], stage=8, block='a')\n",
        "    x = identity_block(x, 3, [f * 8, f * 2, f * 2], stage=8, block='b')\n",
        "    x = identity_block(x, 3, [f * 8, f * 2, f * 2], stage=8, block='d')\n",
        "    x = concatenate([x, x2], axis=bn_axis)\n",
        "\n",
        "    x = up_conv_block(x, 3, [f * 4, f, f], stage=10, block='a', strides=(1, 1))\n",
        "    x = identity_block(x, 3, [f * 4, f, f], stage=10, block='b')\n",
        "    x = identity_block(x, 3, [f * 4, f, f], stage=10, block='c')\n",
        "\n",
        "    x = UpSampling2D(size=(2, 2))(x)\n",
        "    #x = Conv2D(classes, (3, 3), padding='same', activation='sigmoid', name='convLast')(x)\n",
        "    x = Conv2D(classes, (3, 3), padding='same', activation='softmax', name='convLast')(x)\n",
        "\n",
        "    model = Model(input, x, name='resnetUnet')\n",
        "\n",
        "    #model.compile(optimizer=Adam( lr=3e-5), loss=dice_coef_loss, metrics=[dice_coef])\n",
        "    model.compile(optimizer=Adam( lr=0.01), loss= losses.categorical_crossentropy, metrics=[dice_coef, 'accuracy'])\n",
        "       # model.compile(optimizer=Adam(lr=3e-4), loss=dice_coef_loss,\n",
        "        #          metrics=[dice_coef, 'accuracy', precision, recall, f1score])\n",
        "\n",
        "    model.summary()\n",
        "\n",
        "    return model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UNhF6Ml10Ivh",
        "colab_type": "code",
        "outputId": "41c74b83-71cb-4593-f4c5-8b47a90e2a1f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "#realizza il modello Unet per 3 classi\n",
        "model = get_resnet(f=16, bn_axis=3, classes=3)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_3 (InputLayer)            (None, 128, 160, 1)  0                                            \n",
            "__________________________________________________________________________________________________\n",
            "zero_padding2d_3 (ZeroPadding2D (None, 136, 168, 1)  0           input_3[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "conv1 (Conv2D)                  (None, 65, 81, 16)   800         zero_padding2d_3[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "bn_conv1 (BatchNormalization)   (None, 65, 81, 16)   64          conv1[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "activation_147 (Activation)     (None, 65, 81, 16)   0           bn_conv1[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d_3 (MaxPooling2D)  (None, 32, 40, 16)   0           activation_147[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "res2a_branch2a (Conv2D)         (None, 32, 40, 16)   272         max_pooling2d_3[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "bn2a_branch2a (BatchNormalizati (None, 32, 40, 16)   64          res2a_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_148 (Activation)     (None, 32, 40, 16)   0           bn2a_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res2a_branch2b (Conv2D)         (None, 32, 40, 16)   2320        activation_148[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "bn2a_branch2b (BatchNormalizati (None, 32, 40, 16)   64          res2a_branch2b[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_149 (Activation)     (None, 32, 40, 16)   0           bn2a_branch2b[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res2a_branch2c (Conv2D)         (None, 32, 40, 32)   544         activation_149[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "res2a_branch1 (Conv2D)          (None, 32, 40, 32)   544         max_pooling2d_3[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "bn2a_branch2c (BatchNormalizati (None, 32, 40, 32)   128         res2a_branch2c[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "bn2a_branch1 (BatchNormalizatio (None, 32, 40, 32)   128         res2a_branch1[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "add_49 (Add)                    (None, 32, 40, 32)   0           bn2a_branch2c[0][0]              \n",
            "                                                                 bn2a_branch1[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "activation_150 (Activation)     (None, 32, 40, 32)   0           add_49[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "res2b_branch2a (Conv2D)         (None, 32, 40, 16)   528         activation_150[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "bn2b_branch2a (BatchNormalizati (None, 32, 40, 16)   64          res2b_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_151 (Activation)     (None, 32, 40, 16)   0           bn2b_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res2b_branch2b (Conv2D)         (None, 32, 40, 16)   2320        activation_151[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "bn2b_branch2b (BatchNormalizati (None, 32, 40, 16)   64          res2b_branch2b[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_152 (Activation)     (None, 32, 40, 16)   0           bn2b_branch2b[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res2b_branch2c (Conv2D)         (None, 32, 40, 32)   544         activation_152[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "bn2b_branch2c (BatchNormalizati (None, 32, 40, 32)   128         res2b_branch2c[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "add_50 (Add)                    (None, 32, 40, 32)   0           bn2b_branch2c[0][0]              \n",
            "                                                                 activation_150[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_153 (Activation)     (None, 32, 40, 32)   0           add_50[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "res2c_branch2a (Conv2D)         (None, 32, 40, 16)   528         activation_153[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "bn2c_branch2a (BatchNormalizati (None, 32, 40, 16)   64          res2c_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_154 (Activation)     (None, 32, 40, 16)   0           bn2c_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res2c_branch2b (Conv2D)         (None, 32, 40, 16)   2320        activation_154[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "bn2c_branch2b (BatchNormalizati (None, 32, 40, 16)   64          res2c_branch2b[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_155 (Activation)     (None, 32, 40, 16)   0           bn2c_branch2b[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res2c_branch2c (Conv2D)         (None, 32, 40, 32)   544         activation_155[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "bn2c_branch2c (BatchNormalizati (None, 32, 40, 32)   128         res2c_branch2c[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "add_51 (Add)                    (None, 32, 40, 32)   0           bn2c_branch2c[0][0]              \n",
            "                                                                 activation_153[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_156 (Activation)     (None, 32, 40, 32)   0           add_51[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "res3a_branch2a (Conv2D)         (None, 16, 20, 32)   1056        activation_156[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "bn3a_branch2a (BatchNormalizati (None, 16, 20, 32)   128         res3a_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_157 (Activation)     (None, 16, 20, 32)   0           bn3a_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res3a_branch2b (Conv2D)         (None, 16, 20, 32)   9248        activation_157[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "bn3a_branch2b (BatchNormalizati (None, 16, 20, 32)   128         res3a_branch2b[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_158 (Activation)     (None, 16, 20, 32)   0           bn3a_branch2b[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res3a_branch2c (Conv2D)         (None, 16, 20, 64)   2112        activation_158[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "res3a_branch1 (Conv2D)          (None, 16, 20, 64)   2112        activation_156[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "bn3a_branch2c (BatchNormalizati (None, 16, 20, 64)   256         res3a_branch2c[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "bn3a_branch1 (BatchNormalizatio (None, 16, 20, 64)   256         res3a_branch1[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "add_52 (Add)                    (None, 16, 20, 64)   0           bn3a_branch2c[0][0]              \n",
            "                                                                 bn3a_branch1[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "activation_159 (Activation)     (None, 16, 20, 64)   0           add_52[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "res3b_branch2a (Conv2D)         (None, 16, 20, 32)   2080        activation_159[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "bn3b_branch2a (BatchNormalizati (None, 16, 20, 32)   128         res3b_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_160 (Activation)     (None, 16, 20, 32)   0           bn3b_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res3b_branch2b (Conv2D)         (None, 16, 20, 32)   9248        activation_160[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "bn3b_branch2b (BatchNormalizati (None, 16, 20, 32)   128         res3b_branch2b[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_161 (Activation)     (None, 16, 20, 32)   0           bn3b_branch2b[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res3b_branch2c (Conv2D)         (None, 16, 20, 64)   2112        activation_161[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "bn3b_branch2c (BatchNormalizati (None, 16, 20, 64)   256         res3b_branch2c[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "add_53 (Add)                    (None, 16, 20, 64)   0           bn3b_branch2c[0][0]              \n",
            "                                                                 activation_159[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_162 (Activation)     (None, 16, 20, 64)   0           add_53[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "res3d_branch2a (Conv2D)         (None, 16, 20, 32)   2080        activation_162[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "bn3d_branch2a (BatchNormalizati (None, 16, 20, 32)   128         res3d_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_163 (Activation)     (None, 16, 20, 32)   0           bn3d_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res3d_branch2b (Conv2D)         (None, 16, 20, 32)   9248        activation_163[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "bn3d_branch2b (BatchNormalizati (None, 16, 20, 32)   128         res3d_branch2b[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_164 (Activation)     (None, 16, 20, 32)   0           bn3d_branch2b[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res3d_branch2c (Conv2D)         (None, 16, 20, 64)   2112        activation_164[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "bn3d_branch2c (BatchNormalizati (None, 16, 20, 64)   256         res3d_branch2c[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "add_54 (Add)                    (None, 16, 20, 64)   0           bn3d_branch2c[0][0]              \n",
            "                                                                 activation_162[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_165 (Activation)     (None, 16, 20, 64)   0           add_54[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "res4a_branch2a (Conv2D)         (None, 8, 10, 64)    4160        activation_165[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "bn4a_branch2a (BatchNormalizati (None, 8, 10, 64)    256         res4a_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_166 (Activation)     (None, 8, 10, 64)    0           bn4a_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res4a_branch2b (Conv2D)         (None, 8, 10, 64)    36928       activation_166[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "bn4a_branch2b (BatchNormalizati (None, 8, 10, 64)    256         res4a_branch2b[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_167 (Activation)     (None, 8, 10, 64)    0           bn4a_branch2b[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res4a_branch2c (Conv2D)         (None, 8, 10, 128)   8320        activation_167[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "res4a_branch1 (Conv2D)          (None, 8, 10, 128)   8320        activation_165[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "bn4a_branch2c (BatchNormalizati (None, 8, 10, 128)   512         res4a_branch2c[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "bn4a_branch1 (BatchNormalizatio (None, 8, 10, 128)   512         res4a_branch1[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "add_55 (Add)                    (None, 8, 10, 128)   0           bn4a_branch2c[0][0]              \n",
            "                                                                 bn4a_branch1[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "activation_168 (Activation)     (None, 8, 10, 128)   0           add_55[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "res4b_branch2a (Conv2D)         (None, 8, 10, 64)    8256        activation_168[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "bn4b_branch2a (BatchNormalizati (None, 8, 10, 64)    256         res4b_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_169 (Activation)     (None, 8, 10, 64)    0           bn4b_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res4b_branch2b (Conv2D)         (None, 8, 10, 64)    36928       activation_169[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "bn4b_branch2b (BatchNormalizati (None, 8, 10, 64)    256         res4b_branch2b[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_170 (Activation)     (None, 8, 10, 64)    0           bn4b_branch2b[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res4b_branch2c (Conv2D)         (None, 8, 10, 128)   8320        activation_170[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "bn4b_branch2c (BatchNormalizati (None, 8, 10, 128)   512         res4b_branch2c[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "add_56 (Add)                    (None, 8, 10, 128)   0           bn4b_branch2c[0][0]              \n",
            "                                                                 activation_168[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_171 (Activation)     (None, 8, 10, 128)   0           add_56[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "res4f_branch2a (Conv2D)         (None, 8, 10, 64)    8256        activation_171[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "bn4f_branch2a (BatchNormalizati (None, 8, 10, 64)    256         res4f_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_172 (Activation)     (None, 8, 10, 64)    0           bn4f_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res4f_branch2b (Conv2D)         (None, 8, 10, 64)    36928       activation_172[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "bn4f_branch2b (BatchNormalizati (None, 8, 10, 64)    256         res4f_branch2b[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_173 (Activation)     (None, 8, 10, 64)    0           bn4f_branch2b[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res4f_branch2c (Conv2D)         (None, 8, 10, 128)   8320        activation_173[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "bn4f_branch2c (BatchNormalizati (None, 8, 10, 128)   512         res4f_branch2c[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "add_57 (Add)                    (None, 8, 10, 128)   0           bn4f_branch2c[0][0]              \n",
            "                                                                 activation_171[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_174 (Activation)     (None, 8, 10, 128)   0           add_57[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "res5a_branch2a (Conv2D)         (None, 4, 5, 128)    16512       activation_174[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "bn5a_branch2a (BatchNormalizati (None, 4, 5, 128)    512         res5a_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_175 (Activation)     (None, 4, 5, 128)    0           bn5a_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res5a_branch2b (Conv2D)         (None, 4, 5, 128)    147584      activation_175[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "bn5a_branch2b (BatchNormalizati (None, 4, 5, 128)    512         res5a_branch2b[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_176 (Activation)     (None, 4, 5, 128)    0           bn5a_branch2b[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res5a_branch2c (Conv2D)         (None, 4, 5, 256)    33024       activation_176[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "res5a_branch1 (Conv2D)          (None, 4, 5, 256)    33024       activation_174[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "bn5a_branch2c (BatchNormalizati (None, 4, 5, 256)    1024        res5a_branch2c[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "bn5a_branch1 (BatchNormalizatio (None, 4, 5, 256)    1024        res5a_branch1[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "add_58 (Add)                    (None, 4, 5, 256)    0           bn5a_branch2c[0][0]              \n",
            "                                                                 bn5a_branch1[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "activation_177 (Activation)     (None, 4, 5, 256)    0           add_58[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "res5b_branch2a (Conv2D)         (None, 4, 5, 128)    32896       activation_177[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "bn5b_branch2a (BatchNormalizati (None, 4, 5, 128)    512         res5b_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_178 (Activation)     (None, 4, 5, 128)    0           bn5b_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res5b_branch2b (Conv2D)         (None, 4, 5, 128)    147584      activation_178[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "bn5b_branch2b (BatchNormalizati (None, 4, 5, 128)    512         res5b_branch2b[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_179 (Activation)     (None, 4, 5, 128)    0           bn5b_branch2b[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res5b_branch2c (Conv2D)         (None, 4, 5, 256)    33024       activation_179[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "bn5b_branch2c (BatchNormalizati (None, 4, 5, 256)    1024        res5b_branch2c[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "add_59 (Add)                    (None, 4, 5, 256)    0           bn5b_branch2c[0][0]              \n",
            "                                                                 activation_177[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_180 (Activation)     (None, 4, 5, 256)    0           add_59[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "res5c_branch2a (Conv2D)         (None, 4, 5, 128)    32896       activation_180[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "bn5c_branch2a (BatchNormalizati (None, 4, 5, 128)    512         res5c_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_181 (Activation)     (None, 4, 5, 128)    0           bn5c_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res5c_branch2b (Conv2D)         (None, 4, 5, 128)    147584      activation_181[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "bn5c_branch2b (BatchNormalizati (None, 4, 5, 128)    512         res5c_branch2b[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_182 (Activation)     (None, 4, 5, 128)    0           bn5c_branch2b[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res5c_branch2c (Conv2D)         (None, 4, 5, 256)    33024       activation_182[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "bn5c_branch2c (BatchNormalizati (None, 4, 5, 256)    1024        res5c_branch2c[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "add_60 (Add)                    (None, 4, 5, 256)    0           bn5c_branch2c[0][0]              \n",
            "                                                                 activation_180[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_183 (Activation)     (None, 4, 5, 256)    0           add_60[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "up6a_branch2a (UpSampling2D)    (None, 8, 10, 256)   0           activation_183[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "res6a_branch2a (Conv2D)         (None, 8, 10, 256)   65792       up6a_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn6a_branch2a (BatchNormalizati (None, 8, 10, 256)   1024        res6a_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_184 (Activation)     (None, 8, 10, 256)   0           bn6a_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res6a_branch2b (Conv2D)         (None, 8, 10, 128)   295040      activation_184[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "bn6a_branch2b (BatchNormalizati (None, 8, 10, 128)   512         res6a_branch2b[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_185 (Activation)     (None, 8, 10, 128)   0           bn6a_branch2b[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "up6a_branch1 (UpSampling2D)     (None, 8, 10, 256)   0           activation_183[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "res6a_branch2c (Conv2D)         (None, 8, 10, 128)   16512       activation_185[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "res6a_branch1 (Conv2D)          (None, 8, 10, 128)   32896       up6a_branch1[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "bn6a_branch2c (BatchNormalizati (None, 8, 10, 128)   512         res6a_branch2c[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "bn6a_branch1 (BatchNormalizatio (None, 8, 10, 128)   512         res6a_branch1[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "add_61 (Add)                    (None, 8, 10, 128)   0           bn6a_branch2c[0][0]              \n",
            "                                                                 bn6a_branch1[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "activation_186 (Activation)     (None, 8, 10, 128)   0           add_61[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "res6b_branch2a (Conv2D)         (None, 8, 10, 256)   33024       activation_186[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "bn6b_branch2a (BatchNormalizati (None, 8, 10, 256)   1024        res6b_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_187 (Activation)     (None, 8, 10, 256)   0           bn6b_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res6b_branch2b (Conv2D)         (None, 8, 10, 128)   295040      activation_187[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "bn6b_branch2b (BatchNormalizati (None, 8, 10, 128)   512         res6b_branch2b[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_188 (Activation)     (None, 8, 10, 128)   0           bn6b_branch2b[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res6b_branch2c (Conv2D)         (None, 8, 10, 128)   16512       activation_188[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "bn6b_branch2c (BatchNormalizati (None, 8, 10, 128)   512         res6b_branch2c[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "add_62 (Add)                    (None, 8, 10, 128)   0           bn6b_branch2c[0][0]              \n",
            "                                                                 activation_186[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_189 (Activation)     (None, 8, 10, 128)   0           add_62[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "res6c_branch2a (Conv2D)         (None, 8, 10, 256)   33024       activation_189[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "bn6c_branch2a (BatchNormalizati (None, 8, 10, 256)   1024        res6c_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_190 (Activation)     (None, 8, 10, 256)   0           bn6c_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res6c_branch2b (Conv2D)         (None, 8, 10, 128)   295040      activation_190[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "bn6c_branch2b (BatchNormalizati (None, 8, 10, 128)   512         res6c_branch2b[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_191 (Activation)     (None, 8, 10, 128)   0           bn6c_branch2b[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res6c_branch2c (Conv2D)         (None, 8, 10, 128)   16512       activation_191[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "bn6c_branch2c (BatchNormalizati (None, 8, 10, 128)   512         res6c_branch2c[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "add_63 (Add)                    (None, 8, 10, 128)   0           bn6c_branch2c[0][0]              \n",
            "                                                                 activation_189[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_192 (Activation)     (None, 8, 10, 128)   0           add_63[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_7 (Concatenate)     (None, 8, 10, 256)   0           activation_192[0][0]             \n",
            "                                                                 activation_174[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "up7a_branch2a (UpSampling2D)    (None, 16, 20, 256)  0           concatenate_7[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res7a_branch2a (Conv2D)         (None, 16, 20, 256)  65792       up7a_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn7a_branch2a (BatchNormalizati (None, 16, 20, 256)  1024        res7a_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_193 (Activation)     (None, 16, 20, 256)  0           bn7a_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res7a_branch2b (Conv2D)         (None, 16, 20, 64)   147520      activation_193[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "bn7a_branch2b (BatchNormalizati (None, 16, 20, 64)   256         res7a_branch2b[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_194 (Activation)     (None, 16, 20, 64)   0           bn7a_branch2b[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "up7a_branch1 (UpSampling2D)     (None, 16, 20, 256)  0           concatenate_7[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res7a_branch2c (Conv2D)         (None, 16, 20, 64)   4160        activation_194[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "res7a_branch1 (Conv2D)          (None, 16, 20, 64)   16448       up7a_branch1[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "bn7a_branch2c (BatchNormalizati (None, 16, 20, 64)   256         res7a_branch2c[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "bn7a_branch1 (BatchNormalizatio (None, 16, 20, 64)   256         res7a_branch1[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "add_64 (Add)                    (None, 16, 20, 64)   0           bn7a_branch2c[0][0]              \n",
            "                                                                 bn7a_branch1[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "activation_195 (Activation)     (None, 16, 20, 64)   0           add_64[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "res7b_branch2a (Conv2D)         (None, 16, 20, 256)  16640       activation_195[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "bn7b_branch2a (BatchNormalizati (None, 16, 20, 256)  1024        res7b_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_196 (Activation)     (None, 16, 20, 256)  0           bn7b_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res7b_branch2b (Conv2D)         (None, 16, 20, 64)   147520      activation_196[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "bn7b_branch2b (BatchNormalizati (None, 16, 20, 64)   256         res7b_branch2b[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_197 (Activation)     (None, 16, 20, 64)   0           bn7b_branch2b[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res7b_branch2c (Conv2D)         (None, 16, 20, 64)   4160        activation_197[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "bn7b_branch2c (BatchNormalizati (None, 16, 20, 64)   256         res7b_branch2c[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "add_65 (Add)                    (None, 16, 20, 64)   0           bn7b_branch2c[0][0]              \n",
            "                                                                 activation_195[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_198 (Activation)     (None, 16, 20, 64)   0           add_65[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "res7f_branch2a (Conv2D)         (None, 16, 20, 256)  16640       activation_198[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "bn7f_branch2a (BatchNormalizati (None, 16, 20, 256)  1024        res7f_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_199 (Activation)     (None, 16, 20, 256)  0           bn7f_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res7f_branch2b (Conv2D)         (None, 16, 20, 64)   147520      activation_199[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "bn7f_branch2b (BatchNormalizati (None, 16, 20, 64)   256         res7f_branch2b[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_200 (Activation)     (None, 16, 20, 64)   0           bn7f_branch2b[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res7f_branch2c (Conv2D)         (None, 16, 20, 64)   4160        activation_200[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "bn7f_branch2c (BatchNormalizati (None, 16, 20, 64)   256         res7f_branch2c[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "add_66 (Add)                    (None, 16, 20, 64)   0           bn7f_branch2c[0][0]              \n",
            "                                                                 activation_198[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_201 (Activation)     (None, 16, 20, 64)   0           add_66[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_8 (Concatenate)     (None, 16, 20, 128)  0           activation_201[0][0]             \n",
            "                                                                 activation_165[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "up8a_branch2a (UpSampling2D)    (None, 32, 40, 128)  0           concatenate_8[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res8a_branch2a (Conv2D)         (None, 32, 40, 128)  16512       up8a_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn8a_branch2a (BatchNormalizati (None, 32, 40, 128)  512         res8a_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_202 (Activation)     (None, 32, 40, 128)  0           bn8a_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res8a_branch2b (Conv2D)         (None, 32, 40, 32)   36896       activation_202[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "bn8a_branch2b (BatchNormalizati (None, 32, 40, 32)   128         res8a_branch2b[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_203 (Activation)     (None, 32, 40, 32)   0           bn8a_branch2b[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "up8a_branch1 (UpSampling2D)     (None, 32, 40, 128)  0           concatenate_8[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res8a_branch2c (Conv2D)         (None, 32, 40, 32)   1056        activation_203[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "res8a_branch1 (Conv2D)          (None, 32, 40, 32)   4128        up8a_branch1[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "bn8a_branch2c (BatchNormalizati (None, 32, 40, 32)   128         res8a_branch2c[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "bn8a_branch1 (BatchNormalizatio (None, 32, 40, 32)   128         res8a_branch1[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "add_67 (Add)                    (None, 32, 40, 32)   0           bn8a_branch2c[0][0]              \n",
            "                                                                 bn8a_branch1[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "activation_204 (Activation)     (None, 32, 40, 32)   0           add_67[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "res8b_branch2a (Conv2D)         (None, 32, 40, 128)  4224        activation_204[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "bn8b_branch2a (BatchNormalizati (None, 32, 40, 128)  512         res8b_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_205 (Activation)     (None, 32, 40, 128)  0           bn8b_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res8b_branch2b (Conv2D)         (None, 32, 40, 32)   36896       activation_205[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "bn8b_branch2b (BatchNormalizati (None, 32, 40, 32)   128         res8b_branch2b[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_206 (Activation)     (None, 32, 40, 32)   0           bn8b_branch2b[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res8b_branch2c (Conv2D)         (None, 32, 40, 32)   1056        activation_206[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "bn8b_branch2c (BatchNormalizati (None, 32, 40, 32)   128         res8b_branch2c[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "add_68 (Add)                    (None, 32, 40, 32)   0           bn8b_branch2c[0][0]              \n",
            "                                                                 activation_204[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_207 (Activation)     (None, 32, 40, 32)   0           add_68[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "res8d_branch2a (Conv2D)         (None, 32, 40, 128)  4224        activation_207[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "bn8d_branch2a (BatchNormalizati (None, 32, 40, 128)  512         res8d_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_208 (Activation)     (None, 32, 40, 128)  0           bn8d_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res8d_branch2b (Conv2D)         (None, 32, 40, 32)   36896       activation_208[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "bn8d_branch2b (BatchNormalizati (None, 32, 40, 32)   128         res8d_branch2b[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_209 (Activation)     (None, 32, 40, 32)   0           bn8d_branch2b[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res8d_branch2c (Conv2D)         (None, 32, 40, 32)   1056        activation_209[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "bn8d_branch2c (BatchNormalizati (None, 32, 40, 32)   128         res8d_branch2c[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "add_69 (Add)                    (None, 32, 40, 32)   0           bn8d_branch2c[0][0]              \n",
            "                                                                 activation_207[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_210 (Activation)     (None, 32, 40, 32)   0           add_69[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_9 (Concatenate)     (None, 32, 40, 64)   0           activation_210[0][0]             \n",
            "                                                                 activation_156[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "up10a_branch2a (UpSampling2D)   (None, 64, 80, 64)   0           concatenate_9[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res10a_branch2a (Conv2D)        (None, 64, 80, 64)   4160        up10a_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "bn10a_branch2a (BatchNormalizat (None, 64, 80, 64)   256         res10a_branch2a[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "activation_211 (Activation)     (None, 64, 80, 64)   0           bn10a_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "res10a_branch2b (Conv2D)        (None, 64, 80, 16)   9232        activation_211[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "bn10a_branch2b (BatchNormalizat (None, 64, 80, 16)   64          res10a_branch2b[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "activation_212 (Activation)     (None, 64, 80, 16)   0           bn10a_branch2b[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "up10a_branch1 (UpSampling2D)    (None, 64, 80, 64)   0           concatenate_9[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res10a_branch2c (Conv2D)        (None, 64, 80, 16)   272         activation_212[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "res10a_branch1 (Conv2D)         (None, 64, 80, 16)   1040        up10a_branch1[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn10a_branch2c (BatchNormalizat (None, 64, 80, 16)   64          res10a_branch2c[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "bn10a_branch1 (BatchNormalizati (None, 64, 80, 16)   64          res10a_branch1[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "add_70 (Add)                    (None, 64, 80, 16)   0           bn10a_branch2c[0][0]             \n",
            "                                                                 bn10a_branch1[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_213 (Activation)     (None, 64, 80, 16)   0           add_70[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "res10b_branch2a (Conv2D)        (None, 64, 80, 64)   1088        activation_213[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "bn10b_branch2a (BatchNormalizat (None, 64, 80, 64)   256         res10b_branch2a[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "activation_214 (Activation)     (None, 64, 80, 64)   0           bn10b_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "res10b_branch2b (Conv2D)        (None, 64, 80, 16)   9232        activation_214[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "bn10b_branch2b (BatchNormalizat (None, 64, 80, 16)   64          res10b_branch2b[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "activation_215 (Activation)     (None, 64, 80, 16)   0           bn10b_branch2b[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "res10b_branch2c (Conv2D)        (None, 64, 80, 16)   272         activation_215[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "bn10b_branch2c (BatchNormalizat (None, 64, 80, 16)   64          res10b_branch2c[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "add_71 (Add)                    (None, 64, 80, 16)   0           bn10b_branch2c[0][0]             \n",
            "                                                                 activation_213[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_216 (Activation)     (None, 64, 80, 16)   0           add_71[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "res10c_branch2a (Conv2D)        (None, 64, 80, 64)   1088        activation_216[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "bn10c_branch2a (BatchNormalizat (None, 64, 80, 64)   256         res10c_branch2a[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "activation_217 (Activation)     (None, 64, 80, 64)   0           bn10c_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "res10c_branch2b (Conv2D)        (None, 64, 80, 16)   9232        activation_217[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "bn10c_branch2b (BatchNormalizat (None, 64, 80, 16)   64          res10c_branch2b[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "activation_218 (Activation)     (None, 64, 80, 16)   0           bn10c_branch2b[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "res10c_branch2c (Conv2D)        (None, 64, 80, 16)   272         activation_218[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "bn10c_branch2c (BatchNormalizat (None, 64, 80, 16)   64          res10c_branch2c[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "add_72 (Add)                    (None, 64, 80, 16)   0           bn10c_branch2c[0][0]             \n",
            "                                                                 activation_216[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_219 (Activation)     (None, 64, 80, 16)   0           add_72[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "up_sampling2d_3 (UpSampling2D)  (None, 128, 160, 16) 0           activation_219[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "convLast (Conv2D)               (None, 128, 160, 3)  435         up_sampling2d_3[0][0]            \n",
            "==================================================================================================\n",
            "Total params: 2,752,451\n",
            "Trainable params: 2,738,115\n",
            "Non-trainable params: 14,336\n",
            "__________________________________________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ak6nW-Gm0I2l",
        "colab_type": "code",
        "outputId": "d5041ec5-c2af-4c60-8287-1e05416b2aed",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "source": [
        "from keras.utils import to_categorical\n",
        "\n",
        "\n",
        "# suddivisione del dataset in 70% training e 30% test\n",
        "#x_train = array_training[0:1350]\n",
        "#x_test = array_training[1351:1928]\n",
        "\n",
        "#suddivisione del dataset in 7 pazienti per il training e 3 per il test\n",
        "x_train = array_training[0:1288]\n",
        "x_test = array_training[1288:1928]\n",
        "print(x_train.shape)\n",
        "print(x_test.shape)\n",
        "\n",
        "#y_train = array_gt[0:1350]\n",
        "#y_test = array_gt[1351:1928]\n",
        "\n",
        "y_train = array_gt[0:1288]\n",
        "y_test = array_gt[1288:1928]\n",
        "\n",
        "# one hot encoding con tensorflow per 3 classi\n",
        "import tensorflow as tf\n",
        "n_classes = 3 \n",
        "tensor=tf.one_hot(y_train, n_classes)   \n",
        "\n",
        "#trasformaiamo il tensor in numpy array\n",
        "with tf.Session() as sess:\n",
        "   y_train_ohe=sess.run(tensor)\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(1288, 128, 160, 1)\n",
            "(640, 128, 160, 1)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EHHH8hnFofV4",
        "colab_type": "code",
        "outputId": "b4e6fddf-dbdf-4711-d34c-7fee9af037a1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "# alleniamo il modello\n",
        "results = model.fit(x_train, y_train_ohe,validation_split=0.2 ,batch_size=16,epochs=50)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 1030 samples, validate on 258 samples\n",
            "Epoch 1/50\n",
            "1030/1030 [==============================] - 51s 49ms/step - loss: 0.3290 - dice_coef: 0.8304 - acc: 0.8785 - val_loss: 0.3019 - val_dice_coef: 0.8711 - val_acc: 0.8902\n",
            "Epoch 2/50\n",
            "1030/1030 [==============================] - 21s 21ms/step - loss: 0.1815 - dice_coef: 0.9010 - acc: 0.9305 - val_loss: 0.2810 - val_dice_coef: 0.8895 - val_acc: 0.9049\n",
            "Epoch 3/50\n",
            "1030/1030 [==============================] - 21s 21ms/step - loss: 0.1434 - dice_coef: 0.9217 - acc: 0.9456 - val_loss: 0.3020 - val_dice_coef: 0.8998 - val_acc: 0.9115\n",
            "Epoch 4/50\n",
            "1030/1030 [==============================] - 22s 21ms/step - loss: 0.1167 - dice_coef: 0.9362 - acc: 0.9557 - val_loss: 0.3391 - val_dice_coef: 0.9119 - val_acc: 0.9160\n",
            "Epoch 5/50\n",
            "1030/1030 [==============================] - 40s 39ms/step - loss: 0.1113 - dice_coef: 0.9395 - acc: 0.9582 - val_loss: 0.2375 - val_dice_coef: 0.9256 - val_acc: 0.9321\n",
            "Epoch 6/50\n",
            "1030/1030 [==============================] - 59s 57ms/step - loss: 0.0992 - dice_coef: 0.9459 - acc: 0.9625 - val_loss: 0.4330 - val_dice_coef: 0.9115 - val_acc: 0.9142\n",
            "Epoch 7/50\n",
            "1030/1030 [==============================] - 59s 58ms/step - loss: 0.0834 - dice_coef: 0.9541 - acc: 0.9682 - val_loss: 0.5582 - val_dice_coef: 0.8999 - val_acc: 0.9029\n",
            "Epoch 8/50\n",
            "1030/1030 [==============================] - 59s 57ms/step - loss: 0.0795 - dice_coef: 0.9559 - acc: 0.9698 - val_loss: 0.4281 - val_dice_coef: 0.9099 - val_acc: 0.9134\n",
            "Epoch 9/50\n",
            "1030/1030 [==============================] - 60s 58ms/step - loss: 0.0726 - dice_coef: 0.9597 - acc: 0.9721 - val_loss: 0.4731 - val_dice_coef: 0.9116 - val_acc: 0.9154\n",
            "Epoch 10/50\n",
            "1030/1030 [==============================] - 59s 58ms/step - loss: 0.0731 - dice_coef: 0.9595 - acc: 0.9719 - val_loss: 0.4119 - val_dice_coef: 0.9189 - val_acc: 0.9219\n",
            "Epoch 11/50\n",
            "1030/1030 [==============================] - 59s 57ms/step - loss: 0.0642 - dice_coef: 0.9640 - acc: 0.9751 - val_loss: 0.4421 - val_dice_coef: 0.9199 - val_acc: 0.9231\n",
            "Epoch 12/50\n",
            "1030/1030 [==============================] - 59s 57ms/step - loss: 0.0583 - dice_coef: 0.9671 - acc: 0.9771 - val_loss: 0.4744 - val_dice_coef: 0.9153 - val_acc: 0.9183\n",
            "Epoch 13/50\n",
            "1030/1030 [==============================] - 60s 58ms/step - loss: 0.0591 - dice_coef: 0.9668 - acc: 0.9768 - val_loss: 0.4967 - val_dice_coef: 0.9161 - val_acc: 0.9190\n",
            "Epoch 14/50\n",
            "1030/1030 [==============================] - 60s 58ms/step - loss: 0.0567 - dice_coef: 0.9680 - acc: 0.9777 - val_loss: 0.5159 - val_dice_coef: 0.9212 - val_acc: 0.9232\n",
            "Epoch 15/50\n",
            "1030/1030 [==============================] - 59s 58ms/step - loss: 0.0576 - dice_coef: 0.9678 - acc: 0.9773 - val_loss: 0.3668 - val_dice_coef: 0.9263 - val_acc: 0.9300\n",
            "Epoch 16/50\n",
            "1030/1030 [==============================] - 59s 57ms/step - loss: 0.0537 - dice_coef: 0.9696 - acc: 0.9788 - val_loss: 0.5256 - val_dice_coef: 0.9175 - val_acc: 0.9204\n",
            "Epoch 17/50\n",
            "1030/1030 [==============================] - 60s 58ms/step - loss: 0.0508 - dice_coef: 0.9712 - acc: 0.9796 - val_loss: 0.5978 - val_dice_coef: 0.9218 - val_acc: 0.9244\n",
            "Epoch 18/50\n",
            "1030/1030 [==============================] - 59s 57ms/step - loss: 0.0479 - dice_coef: 0.9726 - acc: 0.9807 - val_loss: 0.5092 - val_dice_coef: 0.9167 - val_acc: 0.9194\n",
            "Epoch 19/50\n",
            "1030/1030 [==============================] - 59s 57ms/step - loss: 0.0511 - dice_coef: 0.9711 - acc: 0.9795 - val_loss: 0.4235 - val_dice_coef: 0.9217 - val_acc: 0.9253\n",
            "Epoch 20/50\n",
            "1030/1030 [==============================] - 59s 57ms/step - loss: 0.0492 - dice_coef: 0.9720 - acc: 0.9802 - val_loss: 0.5431 - val_dice_coef: 0.9202 - val_acc: 0.9231\n",
            "Epoch 21/50\n",
            "1030/1030 [==============================] - 59s 57ms/step - loss: 0.0441 - dice_coef: 0.9747 - acc: 0.9821 - val_loss: 0.5872 - val_dice_coef: 0.9173 - val_acc: 0.9202\n",
            "Epoch 22/50\n",
            "1030/1030 [==============================] - 59s 57ms/step - loss: 0.0440 - dice_coef: 0.9748 - acc: 0.9821 - val_loss: 0.6044 - val_dice_coef: 0.9152 - val_acc: 0.9182\n",
            "Epoch 23/50\n",
            "1030/1030 [==============================] - 59s 57ms/step - loss: 0.0451 - dice_coef: 0.9743 - acc: 0.9818 - val_loss: 0.5449 - val_dice_coef: 0.9211 - val_acc: 0.9241\n",
            "Epoch 24/50\n",
            "1030/1030 [==============================] - 60s 58ms/step - loss: 0.0480 - dice_coef: 0.9728 - acc: 0.9806 - val_loss: 0.5970 - val_dice_coef: 0.9167 - val_acc: 0.9194\n",
            "Epoch 25/50\n",
            "1030/1030 [==============================] - 60s 58ms/step - loss: 0.0433 - dice_coef: 0.9752 - acc: 0.9824 - val_loss: 0.6537 - val_dice_coef: 0.9176 - val_acc: 0.9203\n",
            "Epoch 26/50\n",
            "1030/1030 [==============================] - 59s 57ms/step - loss: 0.0417 - dice_coef: 0.9760 - acc: 0.9830 - val_loss: 0.5868 - val_dice_coef: 0.9201 - val_acc: 0.9232\n",
            "Epoch 27/50\n",
            "1030/1030 [==============================] - 59s 58ms/step - loss: 0.0406 - dice_coef: 0.9765 - acc: 0.9833 - val_loss: 0.6013 - val_dice_coef: 0.9227 - val_acc: 0.9253\n",
            "Epoch 28/50\n",
            "1030/1030 [==============================] - 60s 58ms/step - loss: 0.0668 - dice_coef: 0.9638 - acc: 0.9742 - val_loss: 0.7615 - val_dice_coef: 0.9101 - val_acc: 0.9113\n",
            "Epoch 29/50\n",
            "1030/1030 [==============================] - 59s 57ms/step - loss: 0.0562 - dice_coef: 0.9683 - acc: 0.9780 - val_loss: 0.5739 - val_dice_coef: 0.9125 - val_acc: 0.9154\n",
            "Epoch 30/50\n",
            "1030/1030 [==============================] - 59s 57ms/step - loss: 0.0443 - dice_coef: 0.9746 - acc: 0.9820 - val_loss: 0.5471 - val_dice_coef: 0.9194 - val_acc: 0.9220\n",
            "Epoch 31/50\n",
            "1030/1030 [==============================] - 59s 58ms/step - loss: 0.0422 - dice_coef: 0.9757 - acc: 0.9828 - val_loss: 0.5468 - val_dice_coef: 0.9224 - val_acc: 0.9251\n",
            "Epoch 32/50\n",
            "1030/1030 [==============================] - 59s 57ms/step - loss: 0.0408 - dice_coef: 0.9765 - acc: 0.9833 - val_loss: 0.6874 - val_dice_coef: 0.9176 - val_acc: 0.9200\n",
            "Epoch 33/50\n",
            "1030/1030 [==============================] - 59s 58ms/step - loss: 0.0411 - dice_coef: 0.9763 - acc: 0.9832 - val_loss: 0.6535 - val_dice_coef: 0.9179 - val_acc: 0.9204\n",
            "Epoch 34/50\n",
            "1030/1030 [==============================] - 60s 58ms/step - loss: 0.0380 - dice_coef: 0.9780 - acc: 0.9844 - val_loss: 0.6780 - val_dice_coef: 0.9175 - val_acc: 0.9200\n",
            "Epoch 35/50\n",
            "1030/1030 [==============================] - 59s 57ms/step - loss: 0.0371 - dice_coef: 0.9785 - acc: 0.9847 - val_loss: 0.7310 - val_dice_coef: 0.9199 - val_acc: 0.9218\n",
            "Epoch 36/50\n",
            "1030/1030 [==============================] - 59s 58ms/step - loss: 0.0375 - dice_coef: 0.9783 - acc: 0.9846 - val_loss: 0.5988 - val_dice_coef: 0.9245 - val_acc: 0.9270\n",
            "Epoch 37/50\n",
            "1030/1030 [==============================] - 59s 58ms/step - loss: 0.0360 - dice_coef: 0.9791 - acc: 0.9851 - val_loss: 0.7157 - val_dice_coef: 0.9210 - val_acc: 0.9230\n",
            "Epoch 38/50\n",
            "1030/1030 [==============================] - 59s 57ms/step - loss: 0.0354 - dice_coef: 0.9795 - acc: 0.9854 - val_loss: 0.7015 - val_dice_coef: 0.9180 - val_acc: 0.9206\n",
            "Epoch 39/50\n",
            "1030/1030 [==============================] - 59s 57ms/step - loss: 0.0350 - dice_coef: 0.9796 - acc: 0.9855 - val_loss: 0.7001 - val_dice_coef: 0.9185 - val_acc: 0.9207\n",
            "Epoch 40/50\n",
            "1030/1030 [==============================] - 59s 58ms/step - loss: 0.0341 - dice_coef: 0.9802 - acc: 0.9859 - val_loss: 0.7069 - val_dice_coef: 0.9195 - val_acc: 0.9216\n",
            "Epoch 41/50\n",
            "1030/1030 [==============================] - 59s 57ms/step - loss: 0.0341 - dice_coef: 0.9801 - acc: 0.9858 - val_loss: 0.7264 - val_dice_coef: 0.9184 - val_acc: 0.9206\n",
            "Epoch 42/50\n",
            "1030/1030 [==============================] - 59s 58ms/step - loss: 0.0338 - dice_coef: 0.9803 - acc: 0.9859 - val_loss: 0.7312 - val_dice_coef: 0.9203 - val_acc: 0.9225\n",
            "Epoch 43/50\n",
            "1030/1030 [==============================] - 59s 57ms/step - loss: 0.0348 - dice_coef: 0.9799 - acc: 0.9857 - val_loss: 0.5700 - val_dice_coef: 0.9217 - val_acc: 0.9243\n",
            "Epoch 44/50\n",
            "1030/1030 [==============================] - 59s 57ms/step - loss: 0.0377 - dice_coef: 0.9784 - acc: 0.9846 - val_loss: 0.5999 - val_dice_coef: 0.9248 - val_acc: 0.9270\n",
            "Epoch 45/50\n",
            "1030/1030 [==============================] - 59s 58ms/step - loss: 0.0340 - dice_coef: 0.9803 - acc: 0.9859 - val_loss: 0.6962 - val_dice_coef: 0.9211 - val_acc: 0.9232\n",
            "Epoch 46/50\n",
            "1030/1030 [==============================] - 60s 58ms/step - loss: 0.0346 - dice_coef: 0.9798 - acc: 0.9856 - val_loss: 0.6451 - val_dice_coef: 0.9240 - val_acc: 0.9262\n",
            "Epoch 47/50\n",
            "1030/1030 [==============================] - 59s 58ms/step - loss: 0.0324 - dice_coef: 0.9811 - acc: 0.9865 - val_loss: 0.6923 - val_dice_coef: 0.9222 - val_acc: 0.9243\n",
            "Epoch 48/50\n",
            "1030/1030 [==============================] - 59s 57ms/step - loss: 0.0328 - dice_coef: 0.9809 - acc: 0.9864 - val_loss: 0.7806 - val_dice_coef: 0.9183 - val_acc: 0.9202\n",
            "Epoch 49/50\n",
            "1030/1030 [==============================] - 59s 58ms/step - loss: 0.0320 - dice_coef: 0.9813 - acc: 0.9867 - val_loss: 0.6475 - val_dice_coef: 0.9199 - val_acc: 0.9222\n",
            "Epoch 50/50\n",
            "1030/1030 [==============================] - 59s 58ms/step - loss: 0.0319 - dice_coef: 0.9814 - acc: 0.9867 - val_loss: 0.7157 - val_dice_coef: 0.9211 - val_acc: 0.9230\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "drFgYQT2X913",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "print(results.history.keys())\n",
        "\n",
        "# summarize history for loss\n",
        "plt.plot(results.history['val_acc'])\n",
        "plt.title('validation accuracy')\n",
        "plt.ylabel('val_acc')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend('val_acc', loc='upper left')\n",
        "plt.show()\n",
        "\n",
        "\n",
        "# summarize history for loss\n",
        "plt.plot(results.history['loss'])\n",
        "plt.plot(results.history['val_loss'])\n",
        "plt.title('model loss')\n",
        "plt.ylabel('loss')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['loss', 'val_loss'], loc='upper left')\n",
        "plt.show()\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g7RFmxmn0I92",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "# testa il modello\n",
        "predicted_image = model.predict(x_test, verbose = 0)\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KIbF_8GuQ-zy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#funzione dice con numpy arrays\n",
        "def dice(im1, im2, empty_score=1.0):\n",
        "    \"\"\"\n",
        "    Computes the Dice coefficient, a measure of set similarity.\n",
        "    Parameters\n",
        "    ----------\n",
        "    im1 : array-like, bool\n",
        "        Any array of arbitrary size. If not boolean, will be converted.\n",
        "    im2 : array-like, bool\n",
        "        Any other array of identical size. If not boolean, will be converted.\n",
        "    Returns\n",
        "    -------\n",
        "    dice : float\n",
        "        Dice coefficient as a float on range [0,1].\n",
        "        Maximum similarity = 1\n",
        "        No similarity = 0\n",
        "        Both are empty (sum eq to zero) = empty_score\n",
        "        \n",
        "    Notes\n",
        "    -----\n",
        "    The order of inputs for `dice` is irrelevant. The result will be\n",
        "    identical if `im1` and `im2` are switched.\n",
        "    \"\"\"\n",
        "    im1 = np.asarray(im1).astype(np.bool)\n",
        "    im2 = np.asarray(im2).astype(np.bool)\n",
        "\n",
        "    if im1.shape != im2.shape:\n",
        "        raise ValueError(\"Shape mismatch: im1 and im2 must have the same shape.\")\n",
        "\n",
        "    im_sum = im1.sum() + im2.sum()\n",
        "    if im_sum == 0:\n",
        "        return empty_score\n",
        "\n",
        "    # Compute Dice coefficient\n",
        "    intersection = np.logical_and(im1, im2)\n",
        "\n",
        "    return 2. * intersection.sum() / im_sum\n",
        "  \n",
        "  "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vnug3t9Bu8dp",
        "colab_type": "code",
        "outputId": "81af91e7-08c6-420d-970c-9d4a486b0bc2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 556
        }
      },
      "source": [
        "# risultato della predizione, slice 0 con label = 0\n",
        "\n",
        "# round di tutti i valori della predizione\n",
        "predicted_image=np.round(predicted_image,0)\n",
        "\n",
        "\n",
        "image = (predicted_image[126][:, :,0] * 255.).astype(np.uint8)\n",
        "\n",
        "test=tf.one_hot(y_test,3) \n",
        "with tf.Session() as sess:\n",
        "   d=sess.run(test)\n",
        "image1 = (d[126][:, :,0] * 255.).astype(np.uint8)\n",
        "\n",
        "yy_pred=image\n",
        "yy_test=image1\n",
        "\n",
        "print(\"Dice coefficient del slice: \")\n",
        "print(\"--> \",dice(yy_pred,yy_test))\n",
        "\n",
        "img = Image.fromarray(image)  \n",
        "#plot result prediction\n",
        "plt_prediction.imshow(img)\n",
        "plt_prediction.show()\n",
        "\n",
        "\n",
        "\n",
        "# maschera, slice 0 con label = 0 (prima ne facciamo il one-hot-encoding)\n",
        "\n",
        "\n",
        "img = Image.fromarray(image1)\n",
        "plt_maschera.imshow(img)\n",
        "#print ground truth\n",
        "plt_maschera.show()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Dice coefficient del slice: \n",
            "-->  0.9396213657876944\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAATsAAAD8CAYAAAAIRgN/AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nSUVORK5CYII=\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAATsAAAD8CAYAAAAIRgN/AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDMuMC4zLCBo\ndHRwOi8vbWF0cGxvdGxpYi5vcmcvnQurowAAEfdJREFUeJzt3X+MHHd5x/H30zPBTWhxnKSuf4Hd\nYoHSqE6iU5oIVEUE6iRNcSpFURAShkayKtHyU4IYpEb9rwgEpBJNa5GAqaKQ1KSNFVHc1ATRSsXh\nDCa/TODID2LHiU1IQgUSYPP0jx0368vad97Z2Z3d7/slnbwzO3vz3Nd3n3u+M7M3kZlI0qT7jVEX\nIEnDYNhJKoJhJ6kIhp2kIhh2kopg2EkqgmEnqQiNhV1EXB4Rj0bEbETc0NR+JGkhoomLiiNiCvg+\n8FZgP/At4O2Z+cjAdyZJC7Cooc97ETCbmY8BRMSXgI1Az7A7e+lUrln9ioZKkTTJ9jzwix9n5jnz\nbddU2K0Enupa3g/8UfcGEbEZ2AzwmpWLuH/n6oZKkTTJppbPPrmQ7UZ2giIzt2bmdGZOn3PW1KjK\nkFSIpsLuANDdqq2q1knSSDQVdt8C1kXE2og4DbgO2NHQviRpXo0cs8vMIxHxV8BOYAq4NTMfbmJf\nkrQQTZ2gIDO/Anylqc8vSafCd1BIKoJhJ6kIhp2kIhh2kopg2EkqgmEnqQiGnaQiGHaSimDYSSqC\nYSepCIadpCIYdpKKYNhJKoJhJ6kIhp2kIhh2kopg2EkqgmEnqQiGnaQiGHaSimDYSSqCYSepCIad\npCIYdpKKYNhJKsKifl8YEauBLwLLgAS2ZuZNEbEUuANYAzwBXJuZz9cvVapvw4rz2fn03petm2vu\nNhp/dTq7I8CHMvNc4GLgPRFxLnADsCsz1wG7qmVJGqm+O7vMPAgcrB7/b0TsA1YCG4FLq822AV8H\nPlKrSqlPvbq2XutOto1d3mQYyDG7iFgDXADsBpZVQQjwDJ1pbq/XbI6ImYiYOfzc0UGUIUkn1Hdn\nd0xEvAr4MvD+zPxpRPz/c5mZEZG9XpeZW4GtANPrF/fcRurHQjq3Op/PTm881Qq7iHgFnaC7LTPv\nqlY/GxHLM/NgRCwHDtUtUoM3yEBoyw//oENuIftpy9eu+fU9jY1OC3cLsC8zP9X11A5gU/V4E3B3\n/+VJ0mBEZn8zyIh4E/BfwIPAr6vVH6Vz3O5O4DXAk3QuPfnJyT7X9PrFef/O1X3VoZcMq7PRy9nh\njc7U8tk9mTk933Z1zsb+NxAnePqyfj+vJDWh9gkKDZ8dXPv0ulhZ7eLbxSQVwc5uTNjNtd+x/yM7\nvHYy7IbAoCqLoddOTmMlFcHObsDs4qR2srOTVAQ7uxrs4nQyHrtrF8PuFBhu6ofX4LWD01hJRbCz\n62LnJk0uOztJRSius7N70yh4smL0igk7Q05tYOiNjtNYSUUoorOzq1Pb+Kfdh8/OTlIRJrqzs6OT\ndIydnaQiGHaSijCR01inrxonXo4yHHZ2koowcWFnVyepl4kLO0nqpXbYRcRURHwnIu6pltdGxO6I\nmI2IOyLitPplSpPPWUmzBtHZvQ/Y17X8ceDTmfk64Hng+gHsQ5JqqRV2EbEK+FPgc9VyAG8Gtleb\nbAOurrMPSRqEupeefAb4MPBb1fJZwAuZeaRa3g+srLmPBXEKIOlk+u7sIuIq4FBm7unz9ZsjYiYi\nZg4/d7TfMiRpQep0dm8E3hYRVwKLgd8GbgKWRMSiqrtbBRzo9eLM3ApsBZhevzhr1CFNDC8wbk7f\nnV1mbsnMVZm5BrgO+FpmvgO4D7im2mwTcHftKiWppiaus/sI8MGImKVzDO+WBvYhSadkIO+Nzcyv\nA1+vHj8GXDSIz3sqjrX9nqiQ1IvvoJBUBMNOaqENK853ljJghp2kIkxc2HnKXlIvExd2ktSLYSep\nCBMZdjuf3ut0VtJxJjLsJGkuw05SESY67JzOSjpmosNOko4x7CQVwbCTVATDTlIRDDtJRRjI37OT\nNFheRTB4RXR2fuNoXHi5VHOKCDtJMuykEZnbxdnRNcuwk1QET1BIDVlop2ZHNxzFdHYe+JXKVkzY\nSSpbcdNY7y+rpjmDaCc7O0lFqBV2EbEkIrZHxPciYl9EXBIRSyPi3oj4QfXvmYMqdpA8hieVpW5n\ndxPw1cx8A7Ae2AfcAOzKzHXArmpZkkaq77CLiFcDfwzcApCZv8zMF4CNwLZqs23A1XWLlKS66nR2\na4HDwOcj4jsR8bmIOANYlpkHq22eAZbVLbJJTmWlMtQJu0XAhcDNmXkB8DPmTFkzM4Hs9eKI2BwR\nMxExc/i5ozXKkKT51Qm7/cD+zNxdLW+nE37PRsRygOrfQ71enJlbM3M6M6fPOWuqRhn1ebJCg7Rh\nxfle2tRCfYddZj4DPBURr69WXQY8AuwANlXrNgF316pQkgag7kXFfw3cFhGnAY8B76YToHdGxPXA\nk8C1NfchSbXVCrvM3AtM93jqsjqfd1R8d4U0uXwHhaQiGHY9eLJCmjyGnaQiGHaSimDYnYDX3kmT\nxbCTVATDbh52eOqX76RoF8NOUhGK+7Ps/eru7vxtLY0fOztJRbCz64NvK9NCeKy3XQw7tdbcsPCX\ni+pwGiupCHZ2aqVeU0BPEqkOOztJRbCz00id6CB+d+fW64SQXZ5OlWGnkVpIUPXaxoDTqXIaK6kI\nhp2kIhh2korgMbtC+S6Q5vjOiXYy7GqYhMCYhK+hLQy5dnMaK6kIhp2kIhh2kopQK+wi4gMR8XBE\nPBQRt0fE4ohYGxG7I2I2Iu6IiNMGVWxbeaxGar++wy4iVgLvBaYz8zxgCrgO+Djw6cx8HfA8cP0g\nCpWkOupOYxcBvxkRi4DTgYPAm4Ht1fPbgKtr7mMsjNuNeebeDGbc6pdOVd9hl5kHgE8CP6ITci8C\ne4AXMvNItdl+YGXdIsfJuIVGr9CTJlGdaeyZwEZgLbACOAO4/BRevzkiZiJi5vBzR/stQ5IWpM5F\nxW8BHs/MwwARcRfwRmBJRCyqurtVwIFeL87MrcBWgOn1i7NGHRqAY91dd2fqhcbzsxMeH3WO2f0I\nuDgiTo+IAC4DHgHuA66pttkE3F2vREmqr84xu910TkR8G3iw+lxbgY8AH4yIWeAs4JYB1Dl2JuE3\n/rgdfxwmx2b81HpvbGbeCNw4Z/VjwEV1Pq/aZefTe53SdjHkxpPvoJBUBP/qSYMm6UB/afdw7f6/\ns5ObDHZ2kopgZ6e+TNpxvBN1b3Z1kyMyR3+J2/T6xXn/ztWjLmMoxiEgTvUHfBy+ppMx0Mbb1PLZ\nPZk5Pd92TmMlFcHObkTGqRvqp/Np89dnJzdZ7OwkqYudXUu0uROC4XVDJxsHOzL1YmcnSV3s7Fqo\n7V0e2GWpPRba2XmdXQt1B0n3n17qXpZ0apzGSiqCYddyc/+UkNNHqT+GnaQieMxuDLXh+J2XiGjc\nGHZjrA2h18uJ6jEENUpOYyUVwc5uAvTqmNrW7YFTX42WnZ2kItjZTaheFya32dyLp6VBM+wK0OZp\nruGmYXEaK6kIdnaFOlFH1U/HZ3emcWBnJ6kI83Z2EXErcBVwKDPPq9YtBe4A1gBPANdm5vMREcBN\nwJXAz4F3Zea3myldTbBL06RaSGf3BeDyOetuAHZl5jpgV7UMcAWwrvrYDNw8mDIlqZ55wy4zvwH8\nZM7qjcC26vE24Oqu9V/Mjm8CSyJi+aCKlaR+9XvMbllmHqwePwMsqx6vBJ7q2m5/tU6SRqr2CYrs\n/F33U/7b7hGxOSJmImLm8HNH65YhSSfV76Unz0bE8sw8WE1TD1XrDwDdN5NYVa17mczcCmyFzj0o\n+qxDhZvvUhlPuOiYfju7HcCm6vEm4O6u9e+MjouBF7umu5I0Mgu59OR24FLg7IjYD9wI/B1wZ0Rc\nDzwJXFtt/hU6l53M0rn05N0N1KwTaPItYKPskOp8Xb7nVsd4K8UxVMr7Wpv4Og29yeNNsiWpi++N\nHRNt6ea6jeOfX9+w4vxW16fm2NlJKoKdXcu1saObT3fNdlFqCzs7SUUw7FpsHLu6uTasOL/vr2Pn\n03vtDDUwhl0L1QmItmrT1zOJ46v5GXaSiuAJihaZ9G6j33czHNt+0sdHzbKzk1QEw05D1+8xM09W\nqA7DrkU8+zg/x0j9MuwkFcGwk1QEw05SEbz0pIW81GJ+3cftTnWcPOZXJsOuxXY+vdfAWwDDSwvh\nNFZSEezsWm4Sp7R2YhoFOztJRbCzGxN1Dsi3hR2dRsnOTlIR7OzG0Ik6pDZ2fHZzagvDboK0Zapr\nwKmNnMZKKsK8nV1E3ApcBRzKzPOqdZ8A/gz4JfBD4N2Z+UL13BbgeuAo8N7M3NlQ7TqJk3VXg+r6\n7OA0ThbS2X0BuHzOunuB8zLzD4HvA1sAIuJc4DrgD6rX/ENETA2sWknq07ydXWZ+IyLWzFn3H12L\n3wSuqR5vBL6Umb8AHo+IWeAi4H8GUq0Gwo5MJRrEMbu/AP69erwSeKrruf3VOkkaqVphFxEfA44A\nt/Xx2s0RMRMRM4efO1qnDEmaV99hFxHvonPi4h2ZmdXqA8Dqrs1WVeteJjO3ZuZ0Zk6fc5aH9SQ1\nq6+wi4jLgQ8Db8vMn3c9tQO4LiJeGRFrgXXA/fXLlKR6FnLpye3ApcDZEbEfuJHO2ddXAvdGBMA3\nM/MvM/PhiLgTeITO9PY9mekcVdLIxUsz0NGZXr8479+5ev4NJWmOqeWzezJzer7tfAeFpCIYdpKK\nYNhJKoJhJ6kIhp2kIhh2kopg2EkqgmEnqQituKg4Ig4DPwN+POpagLOxjm7WcTzrOF4b6nhtZp4z\n30atCDuAiJhZyFXQ1mEd1mEd/XAaK6kIhp2kIrQp7LaOuoCKdRzPOo5nHcdrSx3zas0xO0lqUps6\nO0lqTCvCLiIuj4hHI2I2Im4Y0j5XR8R9EfFIRDwcEe+r1i+NiHsj4gfVv2cOqZ6piPhORNxTLa+N\niN3VmNwREacNoYYlEbE9Ir4XEfsi4pJRjEdEfKD6P3koIm6PiMXDGo+IuDUiDkXEQ13reo5BdPx9\nVdMDEXFhw3V8ovq/eSAi/jUilnQ9t6Wq49GI2NBkHV3PfSgiMiLOrpYbG49BGHnYVfeV/SxwBXAu\n8Pbq/rNNOwJ8KDPPBS4G3lPt9wZgV2auA3ZVy8PwPmBf1/LHgU9n5uuA5+nceLxpNwFfzcw3AOur\neoY6HhGxEngvMF3dlH2Kzr2IhzUeX+Dl90k+0RhcQefWA+uAzcDNDdcxivs196qDiFgN/Anwo67V\nTY5HfZk50g/gEmBn1/IWYMsI6rgbeCvwKLC8WrcceHQI+15F54fozcA9QNC5UHNRrzFqqIZXA49T\nHcftWj/U8eCl23EupXPbgHuADcMcD2AN8NB8YwD8E/D2Xts1Ucec5/4cuK16fNzPDLATuKTJOoDt\ndH4hPgGcPYzxqPsx8s6OFtxrtroJ+AXAbmBZZh6snnoGWDaEEj5D5wZGv66WzwJeyMwj1fIwxmQt\ncBj4fDWd/lxEnMGQxyMzDwCfpNMxHAReBPYw/PHodqIxGOX37sju1xwRG4EDmfndOU+N/Gf5ZNoQ\ndiMVEa8Cvgy8PzN/2v1cdn49NXq6OiKuAg5l5p4m97MAi4ALgZsz8wI6b987bso6pPE4E9hIJ3xX\nAGfQYxo1KsMYg/nUuV/zAPZ9OvBR4G+Gve+62hB2C77X7KBFxCvoBN1tmXlXtfrZiFhePb8cONRw\nGW8E3hYRTwBfojOVvQlYEhHH7v42jDHZD+zPzN3V8nY64Tfs8XgL8HhmHs7MXwF30RmjYY9HtxON\nwdC/d6Pm/ZoH4Pfp/CL6bvU9uwr4dkT87pDrOGVtCLtvAeuqs22n0TnQuqPpnUZEALcA+zLzU11P\n7QA2VY830TmW15jM3JKZqzJzDZ2v/WuZ+Q7gPuCaIdbxDPBURLy+WnUZnVtiDnU86ExfL46I06v/\no2N1DHU85jjRGOwA3lmdhbwYeLFrujtw0YL7NWfmg5n5O5m5pvqe3Q9cWH3/DHU8TtmoDxpWv5yu\npHN26YfAx4a0zzfRmY48AOytPq6kc7xsF/AD4D+BpUMch0uBe6rHv0fnG3YW+BfglUPY//nATDUm\n/wacOYrxAP4W+B7wEPDPdO5RPJTxAG6nc6zwV3R+kK8/0RjQOZH02er79kE6Z5CbrGOWzjGxY9+v\n/9i1/ceqOh4FrmiyjjnPP8FLJygaG49BfPgOCklFaMM0VpIaZ9hJKoJhJ6kIhp2kIhh2kopg2Ekq\ngmEnqQiGnaQi/B/oYpvWBQZDmAAAAABJRU5ErkJggg==\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Zq4qt6NCtxns",
        "colab_type": "code",
        "outputId": "8b0d5bdb-618f-467a-b46a-f20ef3b491b6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 556
        }
      },
      "source": [
        "# risultato della predizione, slice 0 con label = 1\n",
        "image = (predicted_image[126][:, :,1] * 255.).astype(np.uint8)\n",
        "img = Image.fromarray(image)\n",
        "\n",
        "test=tf.one_hot(y_test,3) \n",
        "\n",
        "with tf.Session() as sess:\n",
        "   d=sess.run(test)\n",
        "image1 = (d[126][:, :,1] * 255.).astype(np.uint8)\n",
        "\n",
        "\n",
        "yy_pred=image\n",
        "yy_test=image1\n",
        "print(\"Dice coefficient del slice: \")\n",
        "print(\"--> \",dice(yy_pred,yy_test))\n",
        "\n",
        "plt_prediction.imshow(img)\n",
        "plt_prediction.show()\n",
        "\n",
        "\n",
        "# maschera, slice 0 con label = 1 (prima ne facciamo il one-hot-encoding)\n",
        "\n",
        "img = Image.fromarray(image1)\n",
        "plt_maschera.imshow(img)\n",
        "plt_maschera.show()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Dice coefficient del slice: \n",
            "-->  0.4166273027869627\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAATsAAAD8CAYAAAAIRgN/AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nYII=\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAATsAAAD8CAYAAAAIRgN/AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDMuMC4zLCBo\ndHRwOi8vbWF0cGxvdGxpYi5vcmcvnQurowAAE+xJREFUeJzt3X/sXXV9x/Hnay0/VlwtX3C1tMx2\ns3FhZAJpAKNbCNUBjlmWEAZhs1OWZombaEy01WTEZH9oNComDtcIUhdCYZWNhjg7qBC3ZDDagfy0\nWvkhrcViBDSaINX3/jjnK6eX+/3e+z2/7rnn83okTe8999xz3vfzPfd935/z66OIwMys735j0gGY\nmbXByc7MkuBkZ2ZJcLIzsyQ42ZlZEpzszCwJTnZmloTGkp2kCyXtk7Rf0uam1mNmNg41cVKxpEXA\nd4B3AAeA+4ErIuKx2ldmZjaGxQ0t92xgf0Q8ASBpO7ABGJrsjtVxcTwnNBSKmfXZT3n+RxHxulHz\nNZXsVgLPFJ4fAM4pziBpE7AJ4HiWcI7WNxSKmfXZXbHj6XHmm9gBiojYGhHrImLdMRw3qTDMLBFN\nJbuDwKmF56vyaWZmE9FUsrsfWCtpjaRjgcuBnQ2ty8xspEb22UXEEUl/B+wCFgE3RMSjTazLzGwc\nTR2gICK+BnytqeWbmS2Er6AwsyQ42ZlZEpzszCwJTnZmlgQnOzNLgpOdmSXByc7MkuBkZ2ZJcLIz\nsyQ42ZlZEpzszCwJTnZmlgQnOzNLgpOdmSXByc7MkuBkZ2ZJcLIzsyQ42ZlZEpzszCwJTnZmlgQn\nOzNLgpOdmSXByc7MkuBkZ2ZJcLIzsyQsLvtGSacCXwGWAwFsjYhrJc0AtwCrgaeAyyLi+eqhmlW3\n6wcPcsEpZ7xq2qDBeWz6VansjgAfiojTgHOB90k6DdgM7I6ItcDu/LmZ2USVruwi4hBwKH/8U0mP\nAyuBDcB5+WzbgHuAj1SK0qykYVXbQt/nKq8fSie7IkmrgTOB+4DleSIEeJasmzvsPZuATQDHs6SO\nMMzM5lQ52Ul6DfBV4AMR8RNJv34tIkJSDHtfRGwFtgIs1czQeczKWOg+uGGvFZcxuDxXetOpUrKT\ndAxZorspIm7LJ/9Q0oqIOCRpBXC4apBWv7Ldu2G68uWvMykV3zu4XHdxp1PpAxTKSrjrgccj4jOF\nl3YCG/PHG4Hby4dnZlYPRZTrQUp6G/BfwMPAr/LJHyXbb3cr8DvA02Snnvx4vmUt1Uyco/Wl4rBX\n1FmtVTGqW9jmepvgU1W65a7YsTci1o2ar8rR2P8GNMfLzlxm1imlK7s6ubJbmLYruKaqloV+ji5V\nT67uumPcys6Xi5lZEmo5z86aV7aaK1NtdGHfX9erpNn4hp2i0vXYU+Vk14K2kse4X7IuJLNB05og\nnPSmh7uxZpYEV3Y1m0TVNKlTParqU+VzwSlnTEWbp8yVnZklwaeeVDDNv+R9qqq6xtfStqvxk4pT\n1ERyG7aDe77rMutYlzVr8G867Iah1j53Y80sCa7sCuo8l22uZc31C1/cwV2lmnMF0R3DqnabHFd2\nZpaE5Cq7On5l56ue5lt+2feVWZ51R7Fq999scpJJdlWT3KiNdJzljzuyVZU4rJsGu7T+O7bP3Vgz\nS0ISlV3TO/wXsvyFHriwfhl1qpE1x5WdmSWh15Vdlyq6hSzX+s/X0rbPlZ2ZJaHXld04mrwHnKs4\nm4+3j3b1MtnVccBgIXwelVXhbacd7saaWRJ6V9lNanxS/yqbdZsrOzNLQuXKTtIiYA9wMCIulrQG\n2A6cBOwF/ioiflF1PZPiis2aVjzR2Ntbc+roxl4NPA4szZ9/EvhsRGyX9EXgKuC6GtbTGG9g1gXe\nDptVqRsraRXwp8CX8ucCzgd25LNsAy6psg4zszpUrew+B3wY+K38+UnACxFxJH9+AFhZcR1jaXMQ\naTObPqUrO0kXA4cjYm/J92+StEfSnpd5qWwYZmZjqdKNfSvwLklPkR2QOB+4FlgmabZiXAUcHPbm\niNgaEesiYt0xHFchjH7wdZJmzSqd7CJiS0SsiojVwOXANyLiSuBu4NJ8to3A7ZWjNDOrqImTij8C\nbJf0j8ADwPUNrKM3XNGZtaOWZBcR9wD35I+fAM6uY7kLMW0jOU1LnGZ94SsozCwJvbs2tut8W3Yb\nh++EUj9XdmaWhN5Vdl2+3XVX45qUccfYTXFwmlQ+Z5t6l+ymTUobdR03VS07CLmZu7FmloReVnZd\nOw1lWBypVCFt/g3GXdfg9pHK3yJ1ruzMLAm9rOy6IuWKrssG/y7+O6VBETHpGFiqmThH6xtb/qju\nTRMbdupfoK7sQqgqpb/ZtLorduyNiHWj5nM31syS4GRntetLVQf9+iypc7IzsyT4AEXNUqwE+v6Z\nfYpKP7iyM7MkuLKj+V9uVwT9kOI1un2SRLIb9+YAdSe9Pn8h+t51HcVd2+njbqyZJSGJym6hdv3g\nQf9iz6Hpiq5Mu0+yyix7F5biNuYqsR2u7MwsCa7shqjjF7Zvv9JNVU9NtPU07E8sxty3baWrkkl2\nXbvtU8qa/nKP6j5amtyNNbMkJFPZzRqnwitzgKLPFUOfPttcY1s0tQ7rDld2ZpaESpWdpGXAl4DT\ngQDeC+wDbgFWA08Bl0XE85WibEDd+/C8T3C0rlU8/pulpWo39lrg6xFxqaRjgSXAR4HdEfEJSZuB\nzcBHKq6ndWXPferaF7qKOpLANLRHG11bm7zS3VhJrwX+GLgeICJ+EREvABuAbfls24BLqgZpZlZV\nlcpuDfAc8GVJbwb2AlcDyyPiUD7Ps8DyaiE2q65BtQeXMQ0VTZOm9fO7a9tfVQ5QLAbOAq6LiDOB\nn5F1WX8tsgEuhg5yIWmTpD2S9rzMSxXCMDMbrfSAO5JeD9wbEavz539EluzeCJwXEYckrQDuiYg3\nzbespgfcGVeV0eb7dH1j1aqmD20wq0pb9KkduqzxAXci4lngGUmziWw98BiwE9iYT9sI3F52HWZm\ndal6NPbvgZvyI7FPAO8hS6C3SroKeBq4rOI6OiGVO6G4kjlaXft0bfIqJbuIeBAYVj5Ovk9awqid\n0/N1Vfv4RR9Xyp/dpoevoDCzJCR3bew4RnVdqhzI6Cp31ebm01H6wZWdmSXBlZ2VNq1VrKXJyW4O\nqXRd+v756pTKNtFX7saaWRJc2Y3Q119zXyXRvD5dVdMHruzMLAmu7MY06p5n0/brXbZinbbP2QRf\nVTGdXNmZWRJc2ZXQ1/14Vi9Xwd3iZFeBN+Z2pXIzBmuGu7FmlgRXdonqWhd8nNvaz3WQyNWejcOV\nnZklwZVdgrpW1cGrq7Nh++fmquZ88q6Nw8kuQV06T2yuRLWQG6Q6ydk43I01syS4sktUV84VdFVm\nbXFlZ2ZJcGVnC+KDAaO5bbrJlV2CBo9q+stZD7dltznZmVkSnOxqMOmd/GY2mpOdmSWhUrKT9EFJ\nj0p6RNLNko6XtEbSfZL2S7pF0rF1BdtVsyfpTkuFV8d+pWn5rGazSic7SSuB9wPrIuJ0YBFwOfBJ\n4LMR8UbgeeCqOgI1M6uiajd2MfCbkhYDS4BDwPnAjvz1bcAlFdcxFWaPxE1ThVdU5kjitH5WS1Pp\nZBcRB4FPA98nS3IvAnuBFyLiSD7bAWBl1SCnybSffjDNsbfFCX46VenGnghsANYApwAnABcu4P2b\nJO2RtOdlXiobhpnZWKpcQfF24MmIeA5A0m3AW4Flkhbn1d0q4OCwN0fEVmArwFLNRIU4rGYLvW62\nD1dVlK3Wpvkzp6bKPrvvA+dKWiJJwHrgMeBu4NJ8no3A7dVCNDOrThHliypJHwf+AjgCPAD8Ddk+\nuu3ATD7tLyNi3n7qUs3EOVpfOg6rbr7qrO9jy5ap6qbtM/bZXbFjb0SsGzVfpRsBRMQ1wDUDk58A\nzq6yXOuWJm/2Oddy20gm7rqmxVdQmFkSfIsnG8t840EMWsj4rnMdDGly9LBxKrpiXK7k+sGVnZkl\nodIBirr0/QDFNJyaUSbGhezzGne5xTiqHhhpIj7rnnEPUDjZ2VHKdNvGTSrzLXfYINltXangRDfd\nxk127saaWRJc2U1IX7u2g+/toi63uS2cKzszswJXdtYp81WErshsGFd2ZmYFPqnYOsXVmzXFlV3H\n+W7AZvVwsjOzJLgb23Hz3XKpzS7fsJN+zaaJKzszS4Iruyk0eKeQNqosV3I27ZzsppgTkNn43I01\nsyS4suupJm9+WZdpiNH6w5WdmSXBlV1PFSulrp42MizGrsRm/eNkl4CuJpDijUK7GqP1h7uxZpYE\nJzs7SpvX4bqaszY52ZlZEkYmO0k3SDos6ZHCtBlJd0r6bv7/ifl0Sfq8pP2SHpJ0VpPBW/1cbVlf\njVPZ3QhcODBtM7A7ItYCu/PnABcBa/N/m4Dr6gnTzKyakckuIr4J/Hhg8gZgW/54G3BJYfpXInMv\nsEzSirqCNTMrq+w+u+URcSh//CywPH+8EnimMN+BfJqZ2URVPkAR2Yg9Cx61R9ImSXsk7XmZl6qG\nYWY2r7InFf9Q0oqIOJR3Uw/n0w8CpxbmW5VPe5WI2ApshWx0sZJxWOJGnSrjAy42q2xltxPYmD/e\nCNxemP7u/KjsucCLhe6umdnEjKzsJN0MnAecLOkAcA3wCeBWSVcBTwOX5bN/DXgnsB/4OfCeBmK2\neQxeY1rmJOHBaqh4WdckFeMY91paX3NrszxItiXBSa+/PEi2mVmBk50l4YJTzuCCU87wGLwJc7Iz\nsyQ42VlSvM8uXU52ZpYEJzszS4KTnZklwcnOzJLgZNchu37woE+NMGuIk52ZJcFDKXZIKqdF+NIt\nmwRXdmaWBCc7M0uCu7Ed5G7eaMUDOQttJ7dvmlzZmVkSXNl1UPEGla4+hiu2y+DpOqPazG2aJie7\nDivekshf0Lm5bWwc7saaWRJc2XXcQsdc6LI+fAabXq7szCwJruymxLAd8tNUIflgi02aKzszS4Ir\nuyk0jRXSNMZs/eLKzsyS4GRnZkkY2Y2VdANwMXA4Ik7Pp30K+DPgF8D3gPdExAv5a1uAq4BfAu+P\niF0NxW4l1XWDUHdNbZqMU9ndCFw4MO1O4PSI+EPgO8AWAEmnAZcDf5C/558kLaotWjOzkkZWdhHx\nTUmrB6b9Z+HpvcCl+eMNwPaIeAl4UtJ+4Gzgf2qJ1mrhisxSVMc+u/cC/5E/Xgk8U3jtQD7NzGyi\nKp16IuljwBHgphLv3QRsAjieJVXCMDMbqXSyk/TXZAcu1kdE5JMPAqcWZluVT3uViNgKbAVYqpkY\nNo+ZWV1KdWMlXQh8GHhXRPy88NJO4HJJx0laA6wF/rd6mGZm1Yxz6snNwHnAyZIOANeQHX09DrhT\nEsC9EfG3EfGopFuBx8i6t++LiF82FbyZ2bj0Sg90cpZqJs7R+kmHYWZT6K7YsTci1o2az1dQmFkS\nnOzMLAlOdmaWBCc7M0uCk52ZJcHJzsyS4GRnZklwsjOzJHTipGJJzwE/A3406ViAk3EcRY7jaI7j\naF2I4w0R8bpRM3Ui2QFI2jPOWdCOw3E4DsdRhruxZpYEJzszS0KXkt3WSQeQcxxHcxxHcxxH60oc\nI3Vmn52ZWZO6VNmZmTWmE8lO0oWS9knaL2lzS+s8VdLdkh6T9Kikq/PpM5LulPTd/P8TW4pnkaQH\nJN2RP18j6b68TW6RdGwLMSyTtEPStyU9Luktk2gPSR/M/yaPSLpZ0vFttYekGyQdlvRIYdrQNlDm\n83lMD0k6q+E4PpX/bR6S9G+SlhVe25LHsU/SBU3GUXjtQ5JC0sn588baow4TT3b5uLJfAC4CTgOu\nyMefbdoR4EMRcRpwLvC+fL2bgd0RsRbYnT9vw9XA44XnnwQ+GxFvBJ4nG3i8adcCX4+I3wfenMfT\nantIWgm8H1iXD8q+iGws4rba40ZePU7yXG1wEdnQA2vJBo+6ruE4JjFe87A4kHQq8CfA9wuTm2yP\n6iJiov+AtwC7Cs+3AFsmEMftwDuAfcCKfNoKYF8L615F9iU6H7gDENmJmouHtVFDMbwWeJJ8P25h\neqvtwSvDcc6QDRtwB3BBm+0BrAYeGdUGwD8DVwybr4k4Bl77c+Cm/PFR3xlgF/CWJuMAdpD9ID4F\nnNxGe1T9N/HKjg6MNZsPAn4mcB+wPCIO5S89CyxvIYTPkQ1g9Kv8+UnACxFxJH/eRpusAZ4Dvpx3\np78k6QRabo+IOAh8mqxiOAS8COyl/fYomqsNJrntTmy8ZkkbgIMR8a2Blyb+XZ5PF5LdREl6DfBV\n4AMR8ZPia5H9PDV6uFrSxcDhiNjb5HrGsBg4C7guIs4ku3zvqC5rS+1xIrCBLPmeApzAkG7UpLTR\nBqNUGa+5hnUvAT4K/EPb666qC8lu7LFm6ybpGLJEd1NE3JZP/qGkFfnrK4DDDYfxVuBdkp4CtpN1\nZa8FlkmaHf2tjTY5AByIiPvy5zvIkl/b7fF24MmIeC4iXgZuI2ujttujaK42aH3b1SvjNV+ZJ962\n4/g9sh+ib+Xb7Crg/yS9vuU4FqwLye5+YG1+tO1Ysh2tO5teqSQB1wOPR8RnCi/tBDbmjzeS7ctr\nTERsiYhVEbGa7LN/IyKuBO4GLm0xjmeBZyS9KZ+0nmxIzFbbg6z7eq6kJfnfaDaOVttjwFxtsBN4\nd34U8lzgxUJ3t3bqwHjNEfFwRPx2RKzOt9kDwFn59tNqeyzYpHca5j9O7yQ7uvQ94GMtrfNtZN2R\nh4AH83/vJNtfthv4LnAXMNNiO5wH3JE//l2yDXY/8K/AcS2s/wxgT94m/w6cOIn2AD4OfBt4BPgX\nsjGKW2kP4GayfYUvk32Rr5qrDcgOJH0h324fJjuC3GQc+8n2ic1ur18szP+xPI59wEVNxjHw+lO8\ncoCisfao45+voDCzJHShG2tm1jgnOzNLgpOdmSXByc7MkuBkZ2ZJcLIzsyQ42ZlZEpzszCwJ/w8d\n7uWGQNb9yQAAAABJRU5ErkJggg==\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mEwJV7ugdQir",
        "colab_type": "code",
        "outputId": "b3b7409e-5e2d-4aa5-c5f5-9e0b4c14d635",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 556
        }
      },
      "source": [
        "# risultato della predizione, slice 0 con label = 2\n",
        "image = (predicted_image[126][:, :,2] * 255.).astype(np.uint8)\n",
        "img = Image.fromarray(image) \n",
        "\n",
        "\n",
        "test=tf.one_hot(y_test,3) \n",
        "\n",
        "with tf.Session() as sess:\n",
        "   d=sess.run(test)\n",
        "\n",
        "image1 = (d[126][:, :,2] * 255.).astype(np.uint8)\n",
        "\n",
        "\n",
        "yy_pred=image\n",
        "yy_test=image1\n",
        "print(\"Dice coefficient del slice: \")\n",
        "print(\"--> \",dice(yy_pred,yy_test))\n",
        "\n",
        "\n",
        "plt_prediction.imshow(img)\n",
        "plt_prediction.show()\n",
        "\n",
        "\n",
        "# maschera, slice 0 con label = 2 (prima ne facciamo il one-hot-encoding)\n",
        "\n",
        "img = Image.fromarray(image1)\n",
        "plt_maschera.imshow(img)\n",
        "plt_maschera.show()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Dice coefficient del slice: \n",
            "-->  0.8994743758212878\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAATsAAAD8CAYAAAAIRgN/AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n+D+aS4NHfOugoAAAAABJRU5ErkJggg==\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAATsAAAD8CAYAAAAIRgN/AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y0f_2cZOs64C",
        "colab_type": "code",
        "outputId": "8481b22e-d520-407f-d82c-50bb2a2b5ec7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 176
        }
      },
      "source": [
        "predicted_image=np.round(predicted_image,0)\n",
        "\n",
        "somma = 0\n",
        "array_dice_background = []\n",
        "\n",
        "for i in range(0,639):\n",
        "  image = (predicted_image[i][:, :,0] * 255.).astype(np.uint8)\n",
        "  image1 = (d[i][:, :,0] * 255.).astype(np.uint8)\n",
        "  yy_pred=image\n",
        "  yy_test=image1\n",
        "  dice_slice = dice(yy_pred,yy_test)\n",
        "  somma += dice_slice\n",
        "  array_dice_background.append(dice_slice)\n",
        "\n",
        "print(\"Dice medio per il Background:   \", somma/640)\n",
        "d_standard = np.std(array_dice_background)\n",
        "print(\"Deviazione standard-Background: \", d_standard)\n",
        "\n",
        "\n",
        "print(\"--------------------->\")\n",
        "\n",
        "somma = 0\n",
        "array_dice_miocardio = []\n",
        "\n",
        "for i in range(0,639):\n",
        "  image = (predicted_image[i][:, :,1] * 255.).astype(np.uint8)\n",
        "  image1 = (d[i][:, :,1] * 255.).astype(np.uint8)\n",
        "  yy_pred=image\n",
        "  yy_test=image1\n",
        "  dice_slice = dice(yy_pred,yy_test)\n",
        "  somma += dice_slice\n",
        "  array_dice_miocardio.append(dice_slice)\n",
        "\n",
        "print(\"Dice medio per il Miocardio:   \", somma/640)\n",
        "deviazione_standard = np.std(array_dice_miocardio)\n",
        "print(\"Deviazione standard-Miocardio: \", deviazione_standard)\n",
        "print(\"------------------------->\")\n",
        "\n",
        "somma = 0\n",
        "array_dice_bloodpool = []\n",
        "\n",
        "for i in range(0,639):\n",
        "  image = (predicted_image[i][:, :,2] * 255.).astype(np.uint8)\n",
        "  image1 = (d[i][:, :,2] * 255.).astype(np.uint8)\n",
        "  yy_pred=image\n",
        "  yy_test=image1\n",
        "  dice_slice = dice(yy_pred,yy_test)\n",
        "  somma += dice_slice\n",
        "  array_dice_bloodpool.append(dice_slice)\n",
        "\n",
        "print(\"Dice medio per il blood Pool:   \", somma/640)\n",
        "deviazione_standard = np.std(array_dice_bloodpool)\n",
        "print(\"Deviazione standard-Blood Pool: \", deviazione_standard)\n",
        "print(\"---------------------------->\")\n",
        "\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Dice medio per il Background:    0.9492458252066923\n",
            "Deviazione standard-Background:  0.03983112413960627\n",
            "--------------------->\n",
            "Dice medio per il Miocardio:    0.2847582730647297\n",
            "Deviazione standard-Miocardio:  0.28126108072740763\n",
            "------------------------->\n",
            "Dice medio per il blood Pool:    0.7416384239668881\n",
            "Deviazione standard-Blood Pool:  0.279067831179658\n",
            "---------------------------->\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jiWyCjXgx3tU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "def calcolo_voxel_bloodpool(array):\n",
        "  print(array.shape)\n",
        "  total = 0\n",
        "  slices = array.shape[0]\n",
        "  rows = array.shape[1]\n",
        "  columns = array.shape[2]\n",
        "  \n",
        "  for slice in range(slices):\n",
        "    for row in range(rows):\n",
        "      for column in range(columns):\n",
        "        print(slice,row,column)\n",
        "        if (np.any(array[slice][row, column, 0] == 2)):\n",
        "          total+=1\n",
        "          print('voxel trovato!')\n",
        "  return total\n",
        "  \n",
        "  \n",
        "  def calcolo_voxel_bloodpool1(array):\n",
        "    result = np.where(array == 2)\n",
        "    print(result)\n",
        " \n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9A25erNq3u4y",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "prediction_paziente_7 = predicted_image[0:250]\n",
        "prediction_paziente_7 = zoom(prediction_paziente_7, (1, 165/prediction_paziente_7.shape[1], 200/prediction_paziente_7.shape[2], 1))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "itjMhh_h3vhi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "prediction_paziente_8 = predicted_image[250:440]\n",
        "prediction_paziente_8 = zoom(prediction_paziente_8, (1, 140/prediction_paziente_8.shape[1], 150/prediction_paziente_8.shape[2], 1))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mgymRh_V32lC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "prediction_paziente_9 = predicted_image[440:640]\n",
        "prediction_paziente_9 = zoom(prediction_paziente_9, (1, 170/prediction_paziente_9.shape[1], 165/prediction_paziente_9.shape[2], 1))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DYbXrM69WkK3",
        "colab_type": "code",
        "outputId": "e9672c07-c2ef-4f77-8470-6d5861f5e721",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 425
        }
      },
      "source": [
        "import numpy.ma as ma\n",
        "\n",
        "\n",
        "prediction_paziente_7 = predicted_image[0:250]\n",
        "prediction_paziente_8 = predicted_image[250:440]\n",
        "prediction_paziente_9 = predicted_image[440:640]\n",
        "\n",
        "# print(prediction_paziente_7.shape)\n",
        "# print(prediction_paziente_7[0][0,0,0])\n",
        "print(\"---------------------------->\")\n",
        "\n",
        "num_voxel_bloodpool_7 =np.sum(prediction_paziente_7[:,:,:,2])\n",
        "num_voxel_bloodpool_8 =np.sum(prediction_paziente_8[:,:,:,2])\n",
        "num_voxel_bloodpool_9 =np.sum(prediction_paziente_9[:,:,:,2])\n",
        "\n",
        "#num_voxel_bloodpool_7 =np.sum(calcolo_voxel_bloodpool(prediction_paziente_7))\n",
        "#num_voxel_bloodpool_8 =np.sum(calcolo_voxel_bloodpool(prediction_paziente_8))\n",
        "#num_voxel_bloodpool_9 =np.sum(calcolo_voxel_bloodpool(prediction_paziente_9))\n",
        "\n",
        "\n",
        "dictionary_num_voxels_prediction = {\n",
        "    7 : num_voxel_bloodpool_7,\n",
        "    8 : num_voxel_bloodpool_8,\n",
        "    9 : num_voxel_bloodpool_9\n",
        "}\n",
        "\n",
        "error_vet = np.arange(3)\n",
        "for x in range (7,10):\n",
        "  print(\"--> Paziente\", x,\":\")\n",
        "  img_gt = nib.load('../content/training_sa_crop_pat%d-label.nii' % (x))\n",
        "  dx,dy,dz= img_gt.header['pixdim'][1:4]\n",
        "  \n",
        "#   print(\"valori dx,dy,dz: \",dx,dy,dz)\n",
        "  \n",
        "  \n",
        "  volume_per_voxel=dx*dy*dz* 1e-3\n",
        "  \n",
        "  #numero totale di voxel\n",
        "  \n",
        "  num_voxel_gt =np.sum(img_gt.get_data() == 2)\n",
        "  \n",
        "  volume_gt = volume_per_voxel * num_voxel_gt\n",
        "  \n",
        "  volume_prediction = volume_per_voxel * dictionary_num_voxels_prediction[x]\n",
        "  \n",
        "  print(\"\\nVolume cuore GROUND TRUE: \")\n",
        "  print(\"-->\",volume_gt)\n",
        "  print(\"Volume cuore PREDICTION: \")\n",
        "  print(\"-->\",volume_prediction)\n",
        "  print(\"------------------------------->\")\n",
        "  error=volume_gt-volume_prediction\n",
        "  error_vet[x-7]=error\n",
        "  \n",
        "  #sommare tutti errori\n",
        "somma=0\n",
        "for x in range(0,error_vet.size):\n",
        "  somma=somma+error_vet[x]\n",
        "mae=somma/error_vet.size\n",
        "\n",
        "print(\"mae: \",mae,\"ml\")"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "---------------------------->\n",
            "--> Paziente 7 :\n",
            "\n",
            "Volume cuore GROUND TRUE: \n",
            "--> 445.55227017661934\n",
            "Volume cuore PREDICTION: \n",
            "--> 245.159910443455\n",
            "------------------------------->\n",
            "--> Paziente 8 :\n",
            "\n",
            "Volume cuore GROUND TRUE: \n",
            "--> 355.71980225539204\n",
            "Volume cuore PREDICTION: \n",
            "--> 349.68586358618734\n",
            "------------------------------->\n",
            "--> Paziente 9 :\n",
            "\n",
            "Volume cuore GROUND TRUE: \n",
            "--> 622.2150389373302\n",
            "Volume cuore PREDICTION: \n",
            "--> 438.12548686051366\n",
            "------------------------------->\n",
            "mae:  130.0 ml\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Bn5cIGrF_qPa",
        "colab_type": "code",
        "outputId": "50091b38-2bf6-496d-99d8-1d3d6ee5fe1c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "print(prediction_paziente_9.shape)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(200, 170, 165, 3)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VKK4TtLLuBm6",
        "colab_type": "code",
        "outputId": "eb757d9f-d652-425d-8f10-628668693e24",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 268
        }
      },
      "source": [
        "prediction_reversed_9 = np.argmax(prediction_paziente_9, axis=3)\n",
        "image1 = (prediction_reversed_9[126][:, :] * 255.)\n",
        "img = Image.fromarray(image1)\n",
        "plt_maschera.imshow(img)\n",
        "plt_maschera.show()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP4AAAD8CAYAAABXXhlaAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDMuMC4zLCBo\ndHRwOi8vbWF0cGxvdGxpYi5vcmcvnQurowAAGFVJREFUeJzt3X+wHWV9x/H3t/wsKEJA0wSohBuw\ng04NTIQ4/hgV9QJFY6cdE6ejqMxk0kHFqKNBZqp/tfijpjpWMrRQoENNELHmD9qAGW2nf9xooOG3\nyA3+ICEQfwziiA0Ev/1j9+RuTvbcs2d/7z6f18yde87ec84+e+5+9/s8z+4+j7k7IhKWP2i6ACJS\nPwW+SIAU+CIBUuCLBEiBLxIgBb5IgCoLfDO7yMweMbNZM1tf1XpEZHJWxXl8MzsC+BHwNmA38APg\nPe7+UOkrE5GJVZXxzwdm3f0xd38O2ASsrGhdIjKhIyv63FOBxxPPdwMXjHrx0XaMH8vxFRVFJBz/\nx295zvfbuNdVFfhjmdkaYA3AsRzHBXZhU0UR6Y3tvi3T66qq6u8BTk88Py1edpC7X+fuy919+VEc\nU1ExRCRNVYH/A+AsM1tiZkcDq4EtFa1LRCZUSVXf3Q+Y2YeArcARwA3u/mAV6xKRyVXWxnf3O4A7\nqvp8EclPV+6JBEiBLxIgBb5IgBT4IgFS4IsESIEvEiAFvkiAFPgiAVLgiwRIgS8SIAW+SIAU+CIB\nUuCLBEiBLxIgBb5IgBT4IgFS4IsEKHfgm9npZvZdM3vIzB40syvj5QvM7C4zezT+fVJ5xRWRMhTJ\n+AeAj7v7OcAK4AozOwdYD2xz97OAbfFzEWmR3IHv7nvd/Z748W+Ah4km0lgJ3BS/7CbgXUULKSLl\nKqWNb2ZnAOcC24GF7r43/tOTwMIy1iEi5Skc+Gb2IuCbwEfd/Znk3zyakTN1Vk4zW2NmO8xsx/Ps\nL1oMEZlAocA3s6OIgv4Wd789XvyUmS2K/74I2Jf2Xs2kI9KcIr36BlwPPOzuX0r8aQtwWfz4MuDb\n+YsnIlUoMqHG64D3Aveb2c542aeBa4Bbzexy4KfAu4sVUUTKljvw3f1/gFHT8WrqW5EW05V7IgFS\n4IsESIEvEiAFvkiAFPgiAVLgiwRIgS8SIAW+SIAU+CIBUuCLBKjItfoilZjdsOKQ50vXzTRUkv5S\nxhcJkDK+tMZwpk9bruxfDmV86ZRRBweZjDJ+R6Tt8H3LfkvXzYwN7F2rNsKquefTi5dVXKp+smhY\nvGadYAv8AtMt/EmjAmDXqo0ATG1ee3BZ3w4Aads+2O48Qjo4bPdtPOO/GjVOxkGq6osEqHBV38yO\nAHYAe9z9UjNbAmwCTgbuBt7r7s8VXU8IkpkumdnTst0hy1Yd9uegstw4W5/Yqe9jSBlt/CuJJtM4\nIX7+OWCDu28ys43A5cC1Jaynt+Zr1xap4o5b5/BntzU4yvgOFPyHKjq89mnAnwH/HD834C3AbfFL\nNJPOGGW3Zwe2PrGTrU/sHPn3tH6Bce+py9J1Mwd/ytSGbWuLom38fwA+Cfw+fn4y8LS7H4if7yaa\nVuswmlBDpDlFxtW/FNjn7nfneb8m1IhU3SOfJ4u3KTNWkfXbtH1NyX06z8z+jmhc/QPAsURt/G8B\n08AfufsBM3st8Fl3n57vs3Q6LzK7YcXIHb2MnXW4jZvWzh/3nqZUEaxt2bYyZT2dV8p5fDN7E/CJ\nuFf/G8A3E51797n71+Z7vwJ/MlkCNk3ajp4loNoUIGUfANq0bWVo8jz+p4CPmdksUZv/+grW0Vmz\nG1Yc/Mn7fjj0Ap6qbX1iZ6Eyl6lvgdqUUi7ZdffvAd+LHz8GnF/G54pINXStfsUmzZJpVdnpxctK\nybZFzmUfbFqsmitTU5LrVkddPrpWv2LjAnbpuplad97hgC1z3U1Xw4tsS9NlL4uu1e+AXas29ipj\nTXqqrIqOur4EcNUU+CIBUhu/YoPz8snsdjArpdxc0weDbR11g9HA1Oa1LGXuHvyyLtYZ9IlUdZ9D\nH6iNX7G2VeXznsuvwtTmtbWMJdC1axWKUBtfWq9vA4h0iar6FWlbph8YlCuZ4QaPmzy7IPVSxhcJ\nkDJ+oNIu5plevKzSrF8ky89XrnGfq9rF4RT4JWtrFT/NcPBHvevNlz9tCLL5aHSdySnwS9SloE9T\n9PRX2qW0WQJy+OrGPOVQ8E9GbXyRACnjl6Sr2b6scqf1F0h7KfBLkDV4xgVDVw8eRUTbHN52N02B\nn1PWS0JDyHxt2cZJ+hVCV3R47RPN7DYz+6GZPWxmrzWzBWZ2l5k9Gv8+qazCtkWXrwMfvoOtzpF8\nkmY3rKishtOGkYLarmjn3peB/3T3PwFeTTSxxnpgm7ufBWyLn4tIixQZXvslwBuJx9Rz9+fc/Wlg\nJdFEGqAJNVpneOy8Pl4vv2vVRmX9MYq08ZcAPwf+xcxeTTRP3pXAQnffG7/mSWBhsSK2x1zVtJzO\nvMM/tz6DW2aLXLRTpC1ddVNp16qNTBE1Y/p4cCuqSFX/SOA84Fp3Pxf4LUPVeo/u+U2977drM+n0\nsce9qfZ93ZT9D1ck8HcDu919e/z8NqIDwVNmtggg/r0v7c2aSUekObmr+u7+pJk9bmavcPdHgAuB\nh+Kfy4Br4t/fLqWkDaoy29dZkxiV4QfLq6x+N3EmJLm+6XU6xZdUtFf/w8AtZnYfsAz4W6KAf5uZ\nPQq8NX4uHdDnqv9gUhCJFLqAx913AstT/tSbcbSKZORR760jw7bBpHfZVU0dfnN05d4IVVbB2xAE\no4wbIDP5uqWMDp62XuQ0KFPoBwDdnScSIGX8FH08dTeJtLZ+Mntn6QtoY7ZPGpSvrE6/rt0noMCX\nTJLBPq563KUDZ9cCtiyq6g/p0k4r5Smr178r+48CPzbpvG+h6nNnWFnNky7sRwp8kQCpjU83jtBN\ny5Lp+/A9ps5xOEZbRieeRPAZvw87axZFOq9CCfqsBs3CwTanfT9t/z6U8WVe8wX9oZ1h7d7R80gb\nsruL2T1N8BlfJERBZ/y2V8faau5y3PC+v6XrZmDV3PNBrSDt/os2XyMQZOCHFPBl7XSDan2oAT+f\nKPijx9Prqp1/sCxBBr5Mpq033DQhS1C3McMPUxt/yPDw011Wxv31Cvp+UuCLBCi4qv6o0zHzzf3W\nhTbbsKnNa3t9eW1Tphd3ow0/TtGZdNaZ2YNm9oCZfd3MjjWzJWa23cxmzWyzmR1dVmGrMq5q34eq\nf94bUEKu5qf934eDvqtNw9wZ38xOBT4CnOPuvzOzW4HVwCXABnffZGYbgcuBa0sprdQm5IAfJRn0\ng/6T+UYharOibfwjgT80syOB44C9wFuIhtoGzaQj0kpFhtfeY2ZfBH4G/A64k2g2nafd/UD8st3A\nqWnvN7M1wBqAYzkubzEmljeTZR2Lri3ytu+7tI1VGa66p7Xpyx7Bp25F5s47iWievCXAYuB44KKs\n72/LhBpZ22dd6ijLexpPQZ8t6Aev62LbfqBIr/5bgR+7+88BzOx24HXAiWZ2ZJz1TwP2FC9meYZ7\nZdt8WWVeaQeppetmUjv4FOyj9aH3fpQibfyfASvM7DgzM+Zm0vku8Jfxa3oxk85A14/yMpn5/tdd\nH7Epd+DHc+bdBtwD3B9/1nXAp4CPmdkscDLxNNoi0h5FZ9L5DPCZocWPAecX+dwqjTpKTzLySls7\n+uY7xaTpo8ZL+7/35YKdYcFduVeG4Vsz22K+Dsi0Nn4bD15d0fUmn67VT9GXO7Aku/n+n8N9O334\n3yvwRQKkqn5PTJqFVM2fXB8y/UBwgZ+1sybL+f3B3+b7vCw3etRJAZ8ubWDNPgsu8NMUvQV3evGy\nwzrO6hxyedyU1QMK+vmFFPxBBn6W23AHQZp1ZxjVo97HU0GSfntul6hzTyRACvwM8mbturJ9lhuI\ndAFPNpP0/wwv61LtToE/ZFSVreuB06W7C9tsXHB3JfiDbOPXoY4doGvtyi4I5TtVxhcJkDJ+BtOL\nl3V2bDXJbtRp0a5U3yehwC9ZW3eStparLcqYfAS601RQ4I/Q9n9g1vLNdUoq8McZ1QHa9TkW0ijw\nS9SXnSIkg6DO2pQbvuT74BgIHTtrMrZzz8xuMLN9ZvZAYtkCM7vLzB6Nf58ULzcz+0o8mcZ9ZnZe\nlYUXkXyyZPwbga8CNyeWrQe2ufs1ZrY+fv4p4GLgrPjnAqKJNC4os8Bt1cZsrwkv55e3OZd8X1c7\nfcdmfHf/b+BXQ4tXEk2WAYdOmrESuNkjM0Qj7i4qq7AiUo685/EXuvve+PGTwML48anA44nXjZxQ\no0/amO1lfm3vvK1a4Qt43N0Bn/R9ZrbGzHaY2Y7n2V+0GCIygbyB/9SgCh//3hcv3wOcnnjdyAk1\n2jKTTp91radZ6pM38LcQTZYBh06asQV4X9y7vwL4daJJIDXr+o1FVZjavLa0i3W6bGyvvpl9HXgT\ncIqZ7SYaR/8a4FYzuxz4KfDu+OV3EE2TPQs8C3yggjKLSEEWNdGbdYIt8AvswqaLkVvdnXuTdEyp\n4/FQfe/U2+7beMZ/ZeNep7vzRAKkwO85tWnn6HuYo2v1S9CF+dXaOt9fXaY2r819lmO+TtKunjlR\nxi9JF9qOIWe8qgK0q2dOFPg9t3TdTGezUht0NbDHUeCLBEiBX6I6qvt51zHI+iF29uXd3rRpxfvS\nT6LOvZK1abSW+aqpg2Doy46cJu8gGeOq97tWbez8wVOBX6Eye/sP7sQl3//d195+DZA6P1X1RQKk\njF+x4TZ509X/Pqt6/Lu02lFXz5go8GuWpw+gyMUn8znY4Ud32/t1t7W73rYfUOA3aHAQSHYmDYIv\nuYNVefFJ8jz/FO1s7yczbVrg1Z11u5rlk9TGb4Fk8A03DercyZaum2ldRhuUZ3rxstRTmX0IwiYo\n8EUCpKp+iySzfpOnopo8xTeuxlFHhg+hFqHA77Gl62YmvrNs3HvK1Ib2eqjGjsBjZjcAlwL73P1V\n8bIvAO8AngN2AR9w96fjv10FXA68AHzE3beOK0TXR+DpimRAjwuwUcGftyYwKpMr0MtV5gg8NwIX\nDS27C3iVu/8p8CPgKgAzOwdYDbwyfs/XzOyICcotIjXINZOOu9/p7gfipzNEw2hDNJPOJnff7+4/\nJhp08/wSyys1GXU776Q3CYV4U1AXlNHG/yCwOX58KhzSKzVyJh0zWwOsATiW40oohoyTp1qdNfiz\n9AuoWt8ehQLfzK4GDgC3TPped78OuA6iNn6RckjzFNTdkjvwzez9RJ1+F/pcD2HmmXREpDm5LuAx\ns4uATwLvdPdnE3/aAqw2s2PMbAnRdNnfL15MESlT3pl0rgKOAe4yM4AZd1/r7g+a2a3AQ0RNgCvc\n/YWqCi8i+WgmHZEe0Uw6IjKSAl8kQLpWXyRhdsOKiS5L7ur9Bsr4IrGybk7qwvBq6twTYS7o67wd\nuYp5GLJ27qmqL8EYDDUGaVm5/iydVjOoaw5GVfVFAqSML70xvm29E1bVUpTWU8aXXuhCh1qbKON3\n2Lidvarx+OsWUlAPtrXqtr4yvkiAlPEbNpzNsh7ps2TBXas2HtamravXuIiQMnxTFPgNStvBtz6x\nc2xwFgmMvAeacZ+Z5XMU0O2hwG/AuADIGkhllWXSdY06YA2kfZ6Cvl0U+B00vXhZqYGUpRYwyfoU\n5O2nzj2RAGUZgeewCTUSf/s48EXgpe7+C4uG4/kycAnwLPB+d7+n/GL3X12ndeZbt9SvTZfs3sjh\nE2pgZqcDbwd+llh8MdE4e2cRDZ19bfEihmnU7LDJv4vklWtCjdgGogE3k7f3rQRu9sgMcKKZLSql\npD1SVlCP+xzpljr/l3lH2V0J7HH3e4f+dCrweOL5yAk1RKQ5Ewe+mR0HfBr4myIrNrM1ZrbDzHY8\nz/4iH9VZaUf4PEf9NmT9NpShiwa1trq/vzyn86aAJcC98dDapwH3mNn5TDChhmbSiZT1Dx/+nCwd\ndKPWnbVzb/j9ecoQsiYPlhMHvrvfD7xs8NzMfgIsj3v1twAfMrNNwAXAr919b1mFleyK7FRZrhPI\n8vnJ1+ggcKima0i5JtRw9+tHvPwOolN5s0Sn8z5QUjmlZk3vmH3Whu92bOC7+3vG/P2MxGMHrihe\nLBGpki7ZlUqpih9pQ5ZPUuBLJRTwc9oW9KDA77T5gqvJnU1B3366SUckQMr4Ugpl+cO1sYo/oMCv\nWFOTJiQnjyiDAnsybQ56UOBXZr5AGTdaTZWyzg83OGhMOolkqNoe6MM0d17J8mTGvDtNlqvrkoGu\nAC5f2wI+69x56twTCZACv0R528Fbn9hZSRta7fJyTW1eCzR3R12Z1MZvkSpG11X1vlxdDvYkZfyW\n6UqWHg6AQTbsm6nNaw9m9z5MRzagjF+SrgRsGaY2r4UNML14btlSZphe16/bcKcXL2Mp/Qn2JGV8\nkQAp8KUSfWkL95UCv4WyVpOnNq9tpG3d9w7DrvfYZ6E2foc1GYC7Vm1kiuig06dOr74H/MDYjG9m\nN5jZPjN7YGj5h83sh2b2oJl9PrH8KjObNbNHzGy6ikKLSDFZMv6NwFeBmwcLzOzNRJNnvNrd95vZ\ny+Ll5wCrgVcCi4HvmNnZ7v5C2QXvuyan0MpqUONI9uZ3WZu/67LlnUnnr4Fr3H1//Jp98fKVwCZ3\n3+/uPyYadPP8EssrsT6cLpPm5O3cOxt4g5ltN7P/MrPXxMs1k44A3TswhZTtIX/n3pHAAmAF8Brg\nVjM7c5IPMLM1RBNrcizH5SyGtFWWsfnbILSAH8ib8XcDt8eTY34f+D1wChPOpOPuy919+VEck7MY\nIpJH3sD/d+DNAGZ2NnA08AtgC7DazI4xsyVE02V/v4yChmpU1gw1U0k5cs2kA9wA3BCf4nsOuCye\nTONBM7sVeAg4AFwRSo9+V6q2faV5+yajEXhKVNXONi67N72Tjypf3cN2TRr8faw1aQQeERlJgV+i\nPmaQIpaum2nsfgIYfy9D0zWlJqmqX5Eyd6osB5QmduJJDnR1lm+4XGkjCx+86rBnB+usVX0FfoW2\nPrHzYMbJ29ad2rw2000wdQd+noCZ9AzFpNs0X5kGwd+nG4rSZA183Z1XoSJV3Enfm9zpqz4I5M2S\nk75vkjMl4z677wE/KbXxRQKkqn6Nss5ik1QkUyWbGmVqInsOMn/a9iibz+lUG9/Mfg78lujqv6ac\novVr/T1Y/8vd/aXjXtSKwAcwsx3uvlzr1/q1/uqpjS8SIAW+SIDaFPjXaf1av9Zfj9a08UWkPm3K\n+CJSk8YD38wuiofinjWz9TWs73Qz+66ZPRQPDX5lvPyzZrbHzHbGP5dUWIafmNn98Xp2xMsWmNld\nZvZo/Pukitb9isQ27jSzZ8zso1Vuf9oQ7aO21yJfifeH+8zsvIrW/4V4ePj7zOxbZnZivPwMM/td\n4nsofF/xiPWP/L5rGaLe3Rv7AY4AdgFnEo3icy9wTsXrXAScFz9+MfAj4Bzgs8AnatrunwCnDC37\nPLA+frwe+FxN3/+TwMur3H7gjcB5wAPjthe4BPgPwIjGdNxe0frfDhwZP/5cYv1nJF9X4fanft/x\nvngvcAywJI6PI8r+nzSd8c8HZt39MXd/DthENER3Zdx9r7vfEz/+DfAw7RgJeCVwU/z4JuBdNazz\nQmCXu/+0ypV4+hDto7Z3JXCzR2aAE81sUdnrd/c73f1A/HSGaHzISozY/lFqGaK+6cBvdDhuMzsD\nOBfYHi/6UFz1u6GqqnbMgTvN7O54tGGAhe6+N378JLCwwvUPrAa+nnhe1/bD6O1tYp/4IFEtY2CJ\nmf1vPHT8Gypcb9r3Xcv2Nx34jTGzFwHfBD7q7s8A1wJTwDJgL/D3Fa7+9e5+HnAxcIWZvTH5R4/q\nfJWebjGzo4F3At+IF9W5/YeoY3tHMbOricaHvCVetBf4Y3c/F/gY8G9mdkIFq27s+4bmAz/zcNxl\nMrOjiIL+Fne/HcDdn3L3F9z998A/UeEMQO6+J/69D/hWvK6nBlXa+Pe+0Z9QiouBe9z9qbgstW1/\nbNT21rZPmNn7gUuBv4oPPsRV7F/Gj+8mamOfXfa65/m+a9n+pgP/B8BZZrYkzkCriYboroyZGXA9\n8LC7fymxPNmO/HPggeH3lrT+483sxYPHRJ1MDxBt92Xxyy4Dvl3F+hPeQ6KaX9f2J4za3i3A++Le\n/RXArxNNgtKY2UXAJ4F3uvuzieUvNbMj4sdnEg0R/1gF6x/1fdczRH3ZvYU5ejwvIepZ3wVcXcP6\nXk9UrbwP2Bn/XAL8K3B/vHwLsKii9Z9J1Gt7L/DgYJuBk4FtwKPAd4AFFX4HxwO/BF6SWFbZ9hMd\nYPYCzxO1WS8ftb1Evfn/GO8P9wPLK1r/LFFberAPbIxf+xfx/2UncA/wjorWP/L7Bq6Ot/8R4OIq\n9gFduScSoKar+iLSAAW+SIAU+CIBUuCLBEiBLxIgBb5IgBT4IgFS4IsE6P8BFvpAoku0TUgAAAAA\nSUVORK5CYII=\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w3RuQq4WAQg7",
        "colab_type": "code",
        "outputId": "5ae2e4cf-639f-45b5-f8ae-d782efd07966",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "#prediction_riconv = zoom(prediction_reversed_9, (1, 170/prediction_reversed_9.shape[1], 165/prediction_reversed_9.shape[2]))\n",
        "prediction_reversed_swappato=np.swapaxes(prediction_reversed_9,1,0)\n",
        "print(prediction_reversed_swappato.shape)\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(170, 200, 165)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "en8P20_wASzU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# new_image.save(\"paziente7.nii\")\n",
        "\n",
        "\n",
        "import nibabel as nib\n",
        "import numpy as np\n",
        "\n",
        "\n",
        "new_image = nib.Nifti1Image(prediction_reversed_swappato, affine=np.eye(4))\n",
        "new_image.set_data_dtype(dtype=np.uint8)\n",
        "\n",
        "import nibabel as nib\n",
        "\n",
        "\n",
        "nib.save(new_image, 'predict3D_paziente_9_myunet')"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}